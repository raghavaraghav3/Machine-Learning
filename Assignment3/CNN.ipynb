{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyPcw/a0iYMSl/NlBn8ytDAq",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/raghavaraghav3/CS-5783/blob/main/Assignment3/Assignment_03_.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Importing Libraries**"
      ],
      "metadata": {
        "id": "QjM52509ETr6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Load the TensorBoard notebook extension.\n",
        "%reload_ext tensorboard\n",
        "\n",
        "from datetime import datetime\n",
        "from packaging import version\n",
        "\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "\n",
        "import tensorboard\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "import numpy as np\n",
        "\n",
        "from keras.datasets import mnist, cifar10\n",
        "\n",
        "from keras.layers import Dense, Flatten, Dropout, Activation, Conv2D, MaxPooling2D, Input\n",
        "from keras.models import Sequential, Model"
      ],
      "metadata": {
        "id": "88J3L4uOEZXc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Question 1**"
      ],
      "metadata": {
        "id": "vecfFIpZGBz-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "(X_Train, Y_Train), (X_Test, Y_Test) = keras.datasets.mnist.load_data() # Downloading the mnist data set"
      ],
      "metadata": {
        "id": "yw1iIxwhFV2G"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"X Train -\", X_Train.shape, \"Y Train -\", Y_Train.shape, \"X Test -\", X_Test.shape, \"Y Test -\", Y_Test.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "23cR64QCFs6p",
        "outputId": "fe7c7b0f-843e-4f68-ac3a-a8c4d6b8962a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "X Train - (60000, 28, 28) Y Train - (60000,) X Test - (10000, 28, 28) Y Test - (10000,)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X_Train = X_Train/255.0\n",
        "X_Test = X_Test/255.0\n",
        "X_Train = X_Train.reshape(-1, 28, 28, 1) #add an additional dimension to represent the single-channel\n",
        "X_Test = X_Test.reshape(-1, 28, 28, 1) #add an additional dimension to represent the single-channel"
      ],
      "metadata": {
        "id": "KuTeZz1xG12Y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**1.1**"
      ],
      "metadata": {
        "id": "xzfFoQq5tHh2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "cnn_model = tf.keras.models.Sequential()\n",
        "\n",
        "cnn_model.add(tf.keras.layers.Conv2D(10, (3, 3), padding='same', activation='relu'))\n",
        "cnn_model.add(tf.keras.layers.Conv2D(20, (3, 3), padding='same', activation='relu'))\n",
        "cnn_model.add(tf.keras.layers.Conv2D(30, (3, 3), padding='same', activation='relu'))\n",
        "\n",
        "cnn_model.add(tf.keras.layers.MaxPooling2D(pool_size=(2, 2), strides=(2,2)))\n",
        "\n",
        "cnn_model.add(tf.keras.layers.Conv2D(40, (3, 3), padding='same', activation='relu'))\n",
        "cnn_model.add(tf.keras.layers.Conv2D(50, (3, 3), padding='same', activation='relu'))\n",
        "cnn_model.add(tf.keras.layers.Conv2D(60, (3, 3), padding='same', activation='relu'))\n",
        "cnn_model.add(tf.keras.layers.Conv2D(70, (3, 3), padding='same', activation='relu'))\n",
        "\n",
        "cnn_model.add(tf.keras.layers.MaxPooling2D(pool_size=(2, 2), strides=(2,2)))\n",
        "\n",
        "cnn_model.add(tf.keras.layers.Conv2D(80, (3, 3), padding='same', activation='relu'))\n",
        "cnn_model.add(tf.keras.layers.Conv2D(90, (3, 3), padding='same', activation='relu'))\n",
        "cnn_model.add(tf.keras.layers.Conv2D(100, (3, 3), padding='same', activation='relu'))\n",
        "\n",
        "cnn_model.add(tf.keras.layers.Flatten())\n",
        "cnn_model.add(tf.keras.layers.Dense(10, activation ='softmax'))\n",
        "\n",
        "cnn_model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=1e-3), loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
        "cnn_model.build(input_shape=(1,28,28,1))\n",
        "cnn_model.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wYW4A1zptEBy",
        "outputId": "2e91c418-6f11-4a1d-edbe-8365c08d99e2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_1\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " conv2d_10 (Conv2D)          (1, 28, 28, 10)           100       \n",
            "                                                                 \n",
            " conv2d_11 (Conv2D)          (1, 28, 28, 20)           1820      \n",
            "                                                                 \n",
            " conv2d_12 (Conv2D)          (1, 28, 28, 30)           5430      \n",
            "                                                                 \n",
            " max_pooling2d_2 (MaxPooling  (1, 14, 14, 30)          0         \n",
            " 2D)                                                             \n",
            "                                                                 \n",
            " conv2d_13 (Conv2D)          (1, 14, 14, 40)           10840     \n",
            "                                                                 \n",
            " conv2d_14 (Conv2D)          (1, 14, 14, 50)           18050     \n",
            "                                                                 \n",
            " conv2d_15 (Conv2D)          (1, 14, 14, 60)           27060     \n",
            "                                                                 \n",
            " conv2d_16 (Conv2D)          (1, 14, 14, 70)           37870     \n",
            "                                                                 \n",
            " max_pooling2d_3 (MaxPooling  (1, 7, 7, 70)            0         \n",
            " 2D)                                                             \n",
            "                                                                 \n",
            " conv2d_17 (Conv2D)          (1, 7, 7, 80)             50480     \n",
            "                                                                 \n",
            " conv2d_18 (Conv2D)          (1, 7, 7, 90)             64890     \n",
            "                                                                 \n",
            " conv2d_19 (Conv2D)          (1, 7, 7, 100)            81100     \n",
            "                                                                 \n",
            " flatten_1 (Flatten)         (1, 4900)                 0         \n",
            "                                                                 \n",
            " dense_1 (Dense)             (1, 10)                   49010     \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 346,650\n",
            "Trainable params: 346,650\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Train and Evaluation with test set"
      ],
      "metadata": {
        "id": "phzkdxKh61ZJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model1 = cnn_model\n",
        "\n",
        "# Train the model\n",
        "model1.fit(X_Train, Y_Train)\n",
        "\n",
        "# Train the model\n",
        "score = model1.evaluate(X_Test, Y_Test)\n",
        "\n",
        "#Results\n",
        "print('Test loss:', score[0])\n",
        "print('Test accuracy:', score[1])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zYMgxCU66Xmn",
        "outputId": "10b63580-5c68-41ce-fef6-c6fd73661cf7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1875/1875 [==============================] - 287s 153ms/step - loss: 0.1271 - accuracy: 0.9603\n",
            "313/313 [==============================] - 13s 41ms/step - loss: 0.0516 - accuracy: 0.9831\n",
            "Test loss: 0.051588188856840134\n",
            "Test accuracy: 0.9830999970436096\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model1_1 = cnn_model\n",
        "\n",
        "# Train the model\n",
        "model1_1.fit(X_Train, Y_Train, batch_size=512, epochs=5)\n",
        "\n",
        "# Train the model\n",
        "score_1 = model1_1.evaluate(X_Test, Y_Test)\n",
        "\n",
        "#Results\n",
        "print('Test loss:', score_1[0])\n",
        "print('Test accuracy:', score_1[1])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "99lGKF3i6_0M",
        "outputId": "07a29907-e56d-46bb-bbc9-70781304ad2e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/5\n",
            "118/118 [==============================] - 428s 4s/step - loss: 0.2312 - accuracy: 0.9308\n",
            "Epoch 2/5\n",
            "118/118 [==============================] - 427s 4s/step - loss: 0.0566 - accuracy: 0.9822\n",
            "Epoch 3/5\n",
            "118/118 [==============================] - 430s 4s/step - loss: 0.0421 - accuracy: 0.9869\n",
            "Epoch 4/5\n",
            "118/118 [==============================] - 428s 4s/step - loss: 0.0316 - accuracy: 0.9904\n",
            "Epoch 5/5\n",
            "118/118 [==============================] - 428s 4s/step - loss: 0.0232 - accuracy: 0.9926\n",
            "313/313 [==============================] - 22s 70ms/step - loss: 0.0268 - accuracy: 0.9915\n",
            "Test loss: 0.026755444705486298\n",
            "Test accuracy: 0.9915000200271606\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**1.1 Explanation**\n",
        "I have used 10 convolution layers between 10 and 100 layers, with the first as 10 and increasing upto 100. The results showed are above. With epoch =5 and batch size = 512, the model performed well with train accuracy = 98.31 and test accuracy to 99.15"
      ],
      "metadata": {
        "id": "SH2W-qR16H6u"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**1.2**"
      ],
      "metadata": {
        "id": "jg8RgR1ROK0o"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "cnn_model2 = tf.keras.models.Sequential()\n",
        "\n",
        "cnn_model2.add(tf.keras.layers.Conv2D(100, (3, 3), padding='same', activation='relu'))\n",
        "cnn_model2.add(tf.keras.layers.Conv2D(90, (3, 3), padding='same', activation='relu'))\n",
        "cnn_model2.add(tf.keras.layers.Conv2D(80, (3, 3), padding='same', activation='relu'))\n",
        "\n",
        "cnn_model2.add(tf.keras.layers.MaxPooling2D(pool_size=(2, 2), strides=(2,2)))\n",
        "\n",
        "cnn_model2.add(tf.keras.layers.Conv2D(70, (3, 3), padding='same', activation='relu'))\n",
        "cnn_model2.add(tf.keras.layers.Conv2D(60, (3, 3), padding='same', activation='relu'))\n",
        "cnn_model2.add(tf.keras.layers.Conv2D(50, (3, 3), padding='same', activation='relu'))\n",
        "cnn_model2.add(tf.keras.layers.Conv2D(40, (3, 3), padding='same', activation='relu'))\n",
        "\n",
        "cnn_model2.add(tf.keras.layers.MaxPooling2D(pool_size=(2, 2), strides=(2,2)))\n",
        "\n",
        "cnn_model2.add(tf.keras.layers.Conv2D(30, (3, 3), padding='same', activation='relu'))\n",
        "cnn_model2.add(tf.keras.layers.Conv2D(20, (3, 3), padding='same', activation='relu'))\n",
        "cnn_model2.add(tf.keras.layers.Conv2D(10, (3, 3), padding='same', activation='relu'))\n",
        "\n",
        "cnn_model2.add(tf.keras.layers.Flatten())\n",
        "cnn_model2.add(tf.keras.layers.Dense(10, activation ='softmax'))\n",
        "\n",
        "cnn_model2.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=1e-3), loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
        "cnn_model2.build(input_shape=(1,28,28,1))\n",
        "cnn_model2.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4E3ZtYhwJ8TM",
        "outputId": "3ef56b58-9959-4823-e148-c97ef0aa369e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_2\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " conv2d_20 (Conv2D)          (1, 28, 28, 100)          1000      \n",
            "                                                                 \n",
            " conv2d_21 (Conv2D)          (1, 28, 28, 90)           81090     \n",
            "                                                                 \n",
            " conv2d_22 (Conv2D)          (1, 28, 28, 80)           64880     \n",
            "                                                                 \n",
            " max_pooling2d_4 (MaxPooling  (1, 14, 14, 80)          0         \n",
            " 2D)                                                             \n",
            "                                                                 \n",
            " conv2d_23 (Conv2D)          (1, 14, 14, 70)           50470     \n",
            "                                                                 \n",
            " conv2d_24 (Conv2D)          (1, 14, 14, 60)           37860     \n",
            "                                                                 \n",
            " conv2d_25 (Conv2D)          (1, 14, 14, 50)           27050     \n",
            "                                                                 \n",
            " conv2d_26 (Conv2D)          (1, 14, 14, 40)           18040     \n",
            "                                                                 \n",
            " max_pooling2d_5 (MaxPooling  (1, 7, 7, 40)            0         \n",
            " 2D)                                                             \n",
            "                                                                 \n",
            " conv2d_27 (Conv2D)          (1, 7, 7, 30)             10830     \n",
            "                                                                 \n",
            " conv2d_28 (Conv2D)          (1, 7, 7, 20)             5420      \n",
            "                                                                 \n",
            " conv2d_29 (Conv2D)          (1, 7, 7, 10)             1810      \n",
            "                                                                 \n",
            " flatten_2 (Flatten)         (1, 490)                  0         \n",
            "                                                                 \n",
            " dense_2 (Dense)             (1, 10)                   4910      \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 303,360\n",
            "Trainable params: 303,360\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model2 = cnn_model2\n",
        "\n",
        "# Train the model\n",
        "model2.fit(X_Train, Y_Train)\n",
        "\n",
        "# Train the model\n",
        "score = model2.evaluate(X_Test, Y_Test)\n",
        "\n",
        "#Results\n",
        "print('Test loss:', score[0])\n",
        "print('Test accuracy:', score[1])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SyklhsfWN1lQ",
        "outputId": "499d66a7-d987-41d1-84cc-4eea3753940a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1875/1875 [==============================] - 845s 450ms/step - loss: 0.1479 - accuracy: 0.9518\n",
            "313/313 [==============================] - 42s 133ms/step - loss: 0.0843 - accuracy: 0.9724\n",
            "Test loss: 0.08425775170326233\n",
            "Test accuracy: 0.9724000096321106\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model2_1 = cnn_model\n",
        "\n",
        "# Train the model\n",
        "model2_1.fit(X_Train, Y_Train, batch_size=512, epochs=5)\n",
        "\n",
        "# Train the model\n",
        "score_2 = model2_1.evaluate(X_Test, Y_Test)\n",
        "\n",
        "#Results\n",
        "print('Test loss:', score_2[0])\n",
        "print('Test accuracy:', score_2[1])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_6UgOdiCEZM8",
        "outputId": "02616d6b-ae88-44ae-9b64-6f74fa36274e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/5\n",
            "118/118 [==============================] - 439s 4s/step - loss: 0.0197 - accuracy: 0.9938\n",
            "Epoch 2/5\n",
            "118/118 [==============================] - 440s 4s/step - loss: 0.0159 - accuracy: 0.9949\n",
            "Epoch 3/5\n",
            "118/118 [==============================] - 432s 4s/step - loss: 0.0144 - accuracy: 0.9954\n",
            "Epoch 4/5\n",
            "118/118 [==============================] - 430s 4s/step - loss: 0.0125 - accuracy: 0.9961\n",
            "Epoch 5/5\n",
            "118/118 [==============================] - 432s 4s/step - loss: 0.0109 - accuracy: 0.9964\n",
            "313/313 [==============================] - 23s 73ms/step - loss: 0.0227 - accuracy: 0.9920\n",
            "Test loss: 0.022745436057448387\n",
            "Test accuracy: 0.9919999837875366\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**1.2 Explanation**\n",
        "I have used 10 convolution layers between 10 and 100 layers, with the first as 100 and decreasing to 10. The results showed are above. With epoch =5 and batch size = 512, the model performed well with train accuracy = 99.20 and test accuracy to 99.19. This model is slightly better than the above method."
      ],
      "metadata": {
        "id": "-cCVMw2YQ91K"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**1.3**"
      ],
      "metadata": {
        "id": "DkWxDQQfGd21"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "cnn_model3 = tf.keras.models.Sequential()\n",
        "\n",
        "cnn_model3.add(tf.keras.layers.Conv2D(10, (3, 3), padding='same', activation='relu'))\n",
        "cnn_model3.add(tf.keras.layers.Conv2D(20, (3, 3), padding='same', activation='relu'))\n",
        "cnn_model3.add(tf.keras.layers.Conv2D(30, (3, 3), padding='same', activation='relu'))\n",
        "\n",
        "cnn_model3.add(tf.keras.layers.MaxPooling2D(pool_size=(2, 2), strides=(2,2)))\n",
        "\n",
        "cnn_model3.add(tf.keras.layers.Conv2D(40, (3, 3), padding='same', activation='relu'))\n",
        "cnn_model3.add(tf.keras.layers.Conv2D(50, (3, 3), padding='same', activation='relu'))\n",
        "cnn_model3.add(tf.keras.layers.Conv2D(60, (3, 3), padding='same', activation='relu'))\n",
        "cnn_model3.add(tf.keras.layers.Conv2D(50, (3, 3), padding='same', activation='relu'))\n",
        "\n",
        "cnn_model3.add(tf.keras.layers.MaxPooling2D(pool_size=(2, 2), strides=(2,2)))\n",
        "\n",
        "cnn_model3.add(tf.keras.layers.Conv2D(40, (3, 3), padding='same', activation='relu'))\n",
        "cnn_model3.add(tf.keras.layers.Conv2D(30, (3, 3), padding='same', activation='relu'))\n",
        "cnn_model3.add(tf.keras.layers.Conv2D(20, (3, 3), padding='same', activation='relu'))\n",
        "\n",
        "cnn_model3.add(tf.keras.layers.Flatten())\n",
        "cnn_model3.add(tf.keras.layers.Dense(10, activation ='softmax'))\n",
        "\n",
        "cnn_model3.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=1e-3) , loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
        "cnn_model3.build(input_shape=(1,28,28,1))\n",
        "cnn_model3.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Hd9l7-UuOxir",
        "outputId": "7beb0d67-b87b-4445-c566-3d0aa96fa665"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_3\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " conv2d_30 (Conv2D)          (1, 28, 28, 10)           100       \n",
            "                                                                 \n",
            " conv2d_31 (Conv2D)          (1, 28, 28, 20)           1820      \n",
            "                                                                 \n",
            " conv2d_32 (Conv2D)          (1, 28, 28, 30)           5430      \n",
            "                                                                 \n",
            " max_pooling2d_6 (MaxPooling  (1, 14, 14, 30)          0         \n",
            " 2D)                                                             \n",
            "                                                                 \n",
            " conv2d_33 (Conv2D)          (1, 14, 14, 40)           10840     \n",
            "                                                                 \n",
            " conv2d_34 (Conv2D)          (1, 14, 14, 50)           18050     \n",
            "                                                                 \n",
            " conv2d_35 (Conv2D)          (1, 14, 14, 60)           27060     \n",
            "                                                                 \n",
            " conv2d_36 (Conv2D)          (1, 14, 14, 50)           27050     \n",
            "                                                                 \n",
            " max_pooling2d_7 (MaxPooling  (1, 7, 7, 50)            0         \n",
            " 2D)                                                             \n",
            "                                                                 \n",
            " conv2d_37 (Conv2D)          (1, 7, 7, 40)             18040     \n",
            "                                                                 \n",
            " conv2d_38 (Conv2D)          (1, 7, 7, 30)             10830     \n",
            "                                                                 \n",
            " conv2d_39 (Conv2D)          (1, 7, 7, 20)             5420      \n",
            "                                                                 \n",
            " flatten_3 (Flatten)         (1, 980)                  0         \n",
            "                                                                 \n",
            " dense_3 (Dense)             (1, 10)                   9810      \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 134,450\n",
            "Trainable params: 134,450\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model3 = cnn_model3\n",
        "\n",
        "# Train the model\n",
        "model3.fit(X_Train, Y_Train)\n",
        "\n",
        "# Train the model\n",
        "score = model3.evaluate(X_Test, Y_Test)\n",
        "\n",
        "# Results\n",
        "print('Test loss:', score[0])\n",
        "print('Test accuracy:', score[1])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mnNmhvkOaTwZ",
        "outputId": "21b8afc3-16f7-4249-f7dd-56bf21972aa5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1875/1875 [==============================] - 417s 222ms/step - loss: 0.1387 - accuracy: 0.9560\n",
            "313/313 [==============================] - 19s 59ms/step - loss: 0.0567 - accuracy: 0.9829\n",
            "Test loss: 0.05666235834360123\n",
            "Test accuracy: 0.9829000234603882\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model3_1 = cnn_model\n",
        "\n",
        "# Train the model\n",
        "model3_1.fit(X_Train, Y_Train, batch_size=512, epochs=5)\n",
        "\n",
        "# Train the model\n",
        "score_3 = model3_1.evaluate(X_Test, Y_Test)\n",
        "\n",
        "#Results\n",
        "print('Test loss:', score_2[0])\n",
        "print('Test accuracy:', score_2[1])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Q1R2KnMQGjzH",
        "outputId": "167e3ddc-73a5-45d4-b921-85640fa73454"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/5\n",
            "118/118 [==============================] - 437s 4s/step - loss: 0.0087 - accuracy: 0.9972\n",
            "Epoch 2/5\n",
            "118/118 [==============================] - 434s 4s/step - loss: 0.0076 - accuracy: 0.9974\n",
            "Epoch 3/5\n",
            "118/118 [==============================] - 430s 4s/step - loss: 0.0076 - accuracy: 0.9974\n",
            "Epoch 4/5\n",
            "118/118 [==============================] - 429s 4s/step - loss: 0.0083 - accuracy: 0.9973\n",
            "Epoch 5/5\n",
            "118/118 [==============================] - 424s 4s/step - loss: 0.0071 - accuracy: 0.9975\n",
            "313/313 [==============================] - 22s 70ms/step - loss: 0.0303 - accuracy: 0.9920\n",
            "Test loss: 0.022745436057448387\n",
            "Test accuracy: 0.9919999837875366\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**1 Explanation**\n",
        "I have used 10 convolution layers same as before. I used between 10 and 60 layers, with the first senario increasing up until 60 and decreasing, till the end to 10 back again. I have used the same parameter as before and this is almost same 1.2"
      ],
      "metadata": {
        "id": "VmeTtdCj4KKe"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Question 2**"
      ],
      "metadata": {
        "id": "Vi0dQVu8kumW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "(X_Train1, Y_Train1), (X_Test1, Y_Test1) = keras.datasets.cifar10.load_data() # Downloading the mnist data set\n",
        "print(X_Train1.shape, \" -- \", Y_Train1.shape, \" -- \", X_Test1.shape,\" -- \", Y_Test1.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kpkShQ_naXJK",
        "outputId": "59f8288a-cc1b-41eb-d9da-5154033d55d1"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz\n",
            "170498071/170498071 [==============================] - 2s 0us/step\n",
            "(50000, 32, 32, 3)  --  (50000, 1)  --  (10000, 32, 32, 3)  --  (10000, 1)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X_Train1 = X_Train1/255.0\n",
        "X_Test1 = X_Test1/255.0"
      ],
      "metadata": {
        "id": "hu5pJIEqlhKl"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "cifar10 = tf.keras.models.Sequential()\n",
        "cifar10.add(tf.keras.layers.Conv2D(6, kernel_size = (5, 5), strides = (1, 1), input_shape = (32, 32, 3), activation='relu'))\n",
        "cifar10.add(tf.keras.layers.MaxPooling2D(pool_size=(2, 2), strides=(2,2)))\n",
        "cifar10.add(tf.keras.layers.Conv2D(16, kernel_size = (5, 5), strides = (1, 1), activation = 'relu'))\n",
        "cifar10.add(tf.keras.layers.MaxPooling2D(pool_size=(2, 2), strides=(2,2)))\n",
        "cifar10.add(tf.keras.layers.Conv2D(120, kernel_size = (5, 5), activation = 'relu'))\n",
        "\n",
        "cifar10.add(tf.keras.layers.Flatten())\n",
        "cifar10.add(tf.keras.layers.Dense(84))\n",
        "cifar10.add(tf.keras.layers.Dense(10, activation='softmax'))\n",
        "\n",
        "cifar10.summary()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HZOBUF6oltg-",
        "outputId": "4d6a726f-04a0-46e7-f3bf-3f940a1ddae7"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_4\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " conv2d_40 (Conv2D)          (None, 28, 28, 6)         456       \n",
            "                                                                 \n",
            " max_pooling2d_8 (MaxPooling  (None, 14, 14, 6)        0         \n",
            " 2D)                                                             \n",
            "                                                                 \n",
            " conv2d_41 (Conv2D)          (None, 10, 10, 16)        2416      \n",
            "                                                                 \n",
            " max_pooling2d_9 (MaxPooling  (None, 5, 5, 16)         0         \n",
            " 2D)                                                             \n",
            "                                                                 \n",
            " conv2d_42 (Conv2D)          (None, 1, 1, 120)         48120     \n",
            "                                                                 \n",
            " flatten_4 (Flatten)         (None, 120)               0         \n",
            "                                                                 \n",
            " dense_4 (Dense)             (None, 84)                10164     \n",
            "                                                                 \n",
            " dense_5 (Dense)             (None, 10)                850       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 62,006\n",
            "Trainable params: 62,006\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "cifar10.compile(loss='sparse_categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "accuracy= cifar10.fit(X_Train1, Y_Train1, epochs=25, batch_size=2000)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-UqLpBc7r2I6",
        "outputId": "883884b5-7ad6-4a72-ab7a-d070f04816f7"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/25\n",
            "25/25 [==============================] - 34s 1s/step - loss: 2.1626 - accuracy: 0.2206\n",
            "Epoch 2/25\n",
            "25/25 [==============================] - 34s 1s/step - loss: 1.8553 - accuracy: 0.3347\n",
            "Epoch 3/25\n",
            "25/25 [==============================] - 31s 1s/step - loss: 1.7104 - accuracy: 0.3858\n",
            "Epoch 4/25\n",
            "25/25 [==============================] - 31s 1s/step - loss: 1.6143 - accuracy: 0.4192\n",
            "Epoch 5/25\n",
            "25/25 [==============================] - 32s 1s/step - loss: 1.5547 - accuracy: 0.4404\n",
            "Epoch 6/25\n",
            "25/25 [==============================] - 31s 1s/step - loss: 1.5122 - accuracy: 0.4557\n",
            "Epoch 7/25\n",
            "25/25 [==============================] - 31s 1s/step - loss: 1.4732 - accuracy: 0.4683\n",
            "Epoch 8/25\n",
            "25/25 [==============================] - 32s 1s/step - loss: 1.4490 - accuracy: 0.4787\n",
            "Epoch 9/25\n",
            "25/25 [==============================] - 31s 1s/step - loss: 1.4221 - accuracy: 0.4897\n",
            "Epoch 10/25\n",
            "25/25 [==============================] - 30s 1s/step - loss: 1.4041 - accuracy: 0.4957\n",
            "Epoch 11/25\n",
            "25/25 [==============================] - 31s 1s/step - loss: 1.3953 - accuracy: 0.4992\n",
            "Epoch 12/25\n",
            "25/25 [==============================] - 32s 1s/step - loss: 1.3729 - accuracy: 0.5088\n",
            "Epoch 13/25\n",
            "25/25 [==============================] - 31s 1s/step - loss: 1.3517 - accuracy: 0.5188\n",
            "Epoch 14/25\n",
            "25/25 [==============================] - 32s 1s/step - loss: 1.3507 - accuracy: 0.5198\n",
            "Epoch 15/25\n",
            "25/25 [==============================] - 31s 1s/step - loss: 1.3343 - accuracy: 0.5242\n",
            "Epoch 16/25\n",
            "25/25 [==============================] - 31s 1s/step - loss: 1.3079 - accuracy: 0.5327\n",
            "Epoch 17/25\n",
            "25/25 [==============================] - 31s 1s/step - loss: 1.2944 - accuracy: 0.5385\n",
            "Epoch 18/25\n",
            "25/25 [==============================] - 32s 1s/step - loss: 1.2870 - accuracy: 0.5431\n",
            "Epoch 19/25\n",
            "25/25 [==============================] - 30s 1s/step - loss: 1.2694 - accuracy: 0.5492\n",
            "Epoch 20/25\n",
            "25/25 [==============================] - 30s 1s/step - loss: 1.2499 - accuracy: 0.5570\n",
            "Epoch 21/25\n",
            "25/25 [==============================] - 32s 1s/step - loss: 1.2521 - accuracy: 0.5587\n",
            "Epoch 22/25\n",
            "25/25 [==============================] - 31s 1s/step - loss: 1.2447 - accuracy: 0.5577\n",
            "Epoch 23/25\n",
            "25/25 [==============================] - 30s 1s/step - loss: 1.2267 - accuracy: 0.5654\n",
            "Epoch 24/25\n",
            "25/25 [==============================] - 32s 1s/step - loss: 1.2157 - accuracy: 0.5702\n",
            "Epoch 25/25\n",
            "25/25 [==============================] - 31s 1s/step - loss: 1.2087 - accuracy: 0.5742\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model_score = cifar10.evaluate(X_Test1, Y_Test1)\n",
        "print('Test loss:', model_score[0])\n",
        "print('Test accuracy:', model_score[1])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1VtkdbRC6p-U",
        "outputId": "a60455c0-8e1b-449f-a6b1-33ba130c1546"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "313/313 [==============================] - 5s 15ms/step - loss: 1.2578 - accuracy: 0.5601\n",
            "Test loss: 1.2577661275863647\n",
            "Test accuracy: 0.5601000189781189\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**2.1**"
      ],
      "metadata": {
        "id": "Vv5D15KB9-tM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "lst_lr = [0.0001, 0.001, 0.005, 0.01, 0.1]\n",
        "loss_acc_lst = []\n",
        "loss_lst = []\n",
        "acc_lst = []\n",
        "\n",
        "for lr in lst_lr:\n",
        "    print(\"For LR = \", lr)\n",
        "    model = tf.keras.models.clone_model(cifar10)\n",
        "    model.compile(loss = 'sparse_categorical_crossentropy', optimizer= tf.keras.optimizers.Adam(learning_rate=lr), metrics=['accuracy'])\n",
        "    model.fit(X_Train1, Y_Train1, epochs=25)\n",
        "    loss, acc = model.evaluate(X_Test1, Y_Test1)\n",
        "    loss_acc_lst.append([loss, acc])\n",
        "    loss_lst.append(loss)\n",
        "    acc_lst.append(acc)\n",
        "    print(\"\\n\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vIqx215R9vpF",
        "outputId": "7dd471e4-86f1-478b-ddf7-828767fe37ae"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "For LR =  0.0001\n",
            "Epoch 1/25\n",
            "1563/1563 [==============================] - 51s 32ms/step - loss: 1.8709 - accuracy: 0.3242\n",
            "Epoch 2/25\n",
            "1563/1563 [==============================] - 49s 31ms/step - loss: 1.5785 - accuracy: 0.4322\n",
            "Epoch 3/25\n",
            "1563/1563 [==============================] - 50s 32ms/step - loss: 1.4845 - accuracy: 0.4678\n",
            "Epoch 4/25\n",
            "1563/1563 [==============================] - 49s 31ms/step - loss: 1.4273 - accuracy: 0.4895\n",
            "Epoch 5/25\n",
            "1563/1563 [==============================] - 50s 32ms/step - loss: 1.3848 - accuracy: 0.5063\n",
            "Epoch 6/25\n",
            "1563/1563 [==============================] - 49s 31ms/step - loss: 1.3509 - accuracy: 0.5206\n",
            "Epoch 7/25\n",
            "1563/1563 [==============================] - 51s 32ms/step - loss: 1.3235 - accuracy: 0.5290\n",
            "Epoch 8/25\n",
            "1563/1563 [==============================] - 49s 32ms/step - loss: 1.2970 - accuracy: 0.5372\n",
            "Epoch 9/25\n",
            "1563/1563 [==============================] - 51s 32ms/step - loss: 1.2753 - accuracy: 0.5472\n",
            "Epoch 10/25\n",
            "1563/1563 [==============================] - 49s 32ms/step - loss: 1.2525 - accuracy: 0.5563\n",
            "Epoch 11/25\n",
            "1563/1563 [==============================] - 51s 32ms/step - loss: 1.2344 - accuracy: 0.5617\n",
            "Epoch 12/25\n",
            "1563/1563 [==============================] - 51s 33ms/step - loss: 1.2157 - accuracy: 0.5704\n",
            "Epoch 13/25\n",
            "1563/1563 [==============================] - 49s 32ms/step - loss: 1.1998 - accuracy: 0.5742\n",
            "Epoch 14/25\n",
            "1563/1563 [==============================] - 50s 32ms/step - loss: 1.1817 - accuracy: 0.5816\n",
            "Epoch 15/25\n",
            "1563/1563 [==============================] - 49s 32ms/step - loss: 1.1668 - accuracy: 0.5866\n",
            "Epoch 16/25\n",
            "1563/1563 [==============================] - 51s 32ms/step - loss: 1.1521 - accuracy: 0.5918\n",
            "Epoch 17/25\n",
            "1563/1563 [==============================] - 50s 32ms/step - loss: 1.1379 - accuracy: 0.5967\n",
            "Epoch 18/25\n",
            "1563/1563 [==============================] - 51s 33ms/step - loss: 1.1239 - accuracy: 0.6041\n",
            "Epoch 19/25\n",
            "1563/1563 [==============================] - 49s 32ms/step - loss: 1.1122 - accuracy: 0.6091\n",
            "Epoch 20/25\n",
            "1563/1563 [==============================] - 52s 34ms/step - loss: 1.0998 - accuracy: 0.6130\n",
            "Epoch 21/25\n",
            "1563/1563 [==============================] - 49s 32ms/step - loss: 1.0867 - accuracy: 0.6177\n",
            "Epoch 22/25\n",
            "1563/1563 [==============================] - 51s 33ms/step - loss: 1.0776 - accuracy: 0.6216\n",
            "Epoch 23/25\n",
            "1563/1563 [==============================] - 51s 32ms/step - loss: 1.0647 - accuracy: 0.6262\n",
            "Epoch 24/25\n",
            "1563/1563 [==============================] - 49s 32ms/step - loss: 1.0545 - accuracy: 0.6296\n",
            "Epoch 25/25\n",
            "1563/1563 [==============================] - 51s 32ms/step - loss: 1.0443 - accuracy: 0.6317\n",
            "313/313 [==============================] - 5s 15ms/step - loss: 1.1638 - accuracy: 0.5922\n",
            "\n",
            "\n",
            "For LR =  0.001\n",
            "Epoch 1/25\n",
            "1563/1563 [==============================] - 51s 32ms/step - loss: 1.5738 - accuracy: 0.4220\n",
            "Epoch 2/25\n",
            "1563/1563 [==============================] - 49s 31ms/step - loss: 1.3078 - accuracy: 0.5298\n",
            "Epoch 3/25\n",
            "1563/1563 [==============================] - 51s 32ms/step - loss: 1.2079 - accuracy: 0.5681\n",
            "Epoch 4/25\n",
            "1563/1563 [==============================] - 50s 32ms/step - loss: 1.1382 - accuracy: 0.5974\n",
            "Epoch 5/25\n",
            "1563/1563 [==============================] - 50s 32ms/step - loss: 1.0784 - accuracy: 0.6171\n",
            "Epoch 6/25\n",
            "1563/1563 [==============================] - 49s 32ms/step - loss: 1.0359 - accuracy: 0.6339\n",
            "Epoch 7/25\n",
            "1563/1563 [==============================] - 51s 32ms/step - loss: 0.9937 - accuracy: 0.6471\n",
            "Epoch 8/25\n",
            "1563/1563 [==============================] - 51s 33ms/step - loss: 0.9667 - accuracy: 0.6573\n",
            "Epoch 9/25\n",
            "1563/1563 [==============================] - 49s 31ms/step - loss: 0.9371 - accuracy: 0.6691\n",
            "Epoch 10/25\n",
            "1563/1563 [==============================] - 51s 32ms/step - loss: 0.9113 - accuracy: 0.6786\n",
            "Epoch 11/25\n",
            "1563/1563 [==============================] - 49s 31ms/step - loss: 0.8881 - accuracy: 0.6847\n",
            "Epoch 12/25\n",
            "1563/1563 [==============================] - 51s 32ms/step - loss: 0.8611 - accuracy: 0.6952\n",
            "Epoch 13/25\n",
            "1563/1563 [==============================] - 50s 32ms/step - loss: 0.8412 - accuracy: 0.7019\n",
            "Epoch 14/25\n",
            "1563/1563 [==============================] - 51s 32ms/step - loss: 0.8246 - accuracy: 0.7087\n",
            "Epoch 15/25\n",
            "1563/1563 [==============================] - 51s 32ms/step - loss: 0.8013 - accuracy: 0.7156\n",
            "Epoch 16/25\n",
            "1563/1563 [==============================] - 49s 32ms/step - loss: 0.7850 - accuracy: 0.7205\n",
            "Epoch 17/25\n",
            "1563/1563 [==============================] - 51s 32ms/step - loss: 0.7699 - accuracy: 0.7257\n",
            "Epoch 18/25\n",
            "1563/1563 [==============================] - 49s 31ms/step - loss: 0.7568 - accuracy: 0.7293\n",
            "Epoch 19/25\n",
            "1563/1563 [==============================] - 51s 32ms/step - loss: 0.7372 - accuracy: 0.7370\n",
            "Epoch 20/25\n",
            "1563/1563 [==============================] - 49s 31ms/step - loss: 0.7266 - accuracy: 0.7402\n",
            "Epoch 21/25\n",
            "1563/1563 [==============================] - 51s 32ms/step - loss: 0.7116 - accuracy: 0.7461\n",
            "Epoch 22/25\n",
            "1563/1563 [==============================] - 50s 32ms/step - loss: 0.6992 - accuracy: 0.7513\n",
            "Epoch 23/25\n",
            "1563/1563 [==============================] - 49s 31ms/step - loss: 0.6878 - accuracy: 0.7556\n",
            "Epoch 24/25\n",
            "1563/1563 [==============================] - 50s 32ms/step - loss: 0.6757 - accuracy: 0.7588\n",
            "Epoch 25/25\n",
            "1563/1563 [==============================] - 49s 32ms/step - loss: 0.6677 - accuracy: 0.7601\n",
            "313/313 [==============================] - 6s 19ms/step - loss: 1.3461 - accuracy: 0.6030\n",
            "\n",
            "\n",
            "For LR =  0.005\n",
            "Epoch 1/25\n",
            "1563/1563 [==============================] - 49s 31ms/step - loss: 1.9744 - accuracy: 0.2561\n",
            "Epoch 2/25\n",
            "1563/1563 [==============================] - 50s 32ms/step - loss: 1.7457 - accuracy: 0.3569\n",
            "Epoch 3/25\n",
            "1563/1563 [==============================] - 49s 31ms/step - loss: 1.6658 - accuracy: 0.3975\n",
            "Epoch 4/25\n",
            "1563/1563 [==============================] - 50s 32ms/step - loss: 1.6246 - accuracy: 0.4164\n",
            "Epoch 5/25\n",
            "1563/1563 [==============================] - 49s 31ms/step - loss: 1.6059 - accuracy: 0.4231\n",
            "Epoch 6/25\n",
            "1563/1563 [==============================] - 50s 32ms/step - loss: 1.5928 - accuracy: 0.4298\n",
            "Epoch 7/25\n",
            "1563/1563 [==============================] - 50s 32ms/step - loss: 1.5734 - accuracy: 0.4346\n",
            "Epoch 8/25\n",
            "1563/1563 [==============================] - 49s 31ms/step - loss: 1.5635 - accuracy: 0.4385\n",
            "Epoch 9/25\n",
            "1563/1563 [==============================] - 50s 32ms/step - loss: 1.5633 - accuracy: 0.4394\n",
            "Epoch 10/25\n",
            "1563/1563 [==============================] - 49s 31ms/step - loss: 1.5630 - accuracy: 0.4388\n",
            "Epoch 11/25\n",
            "1563/1563 [==============================] - 50s 32ms/step - loss: 1.5519 - accuracy: 0.4459\n",
            "Epoch 12/25\n",
            "1563/1563 [==============================] - 49s 31ms/step - loss: 1.5516 - accuracy: 0.4442\n",
            "Epoch 13/25\n",
            "1563/1563 [==============================] - 50s 32ms/step - loss: 1.5444 - accuracy: 0.4452\n",
            "Epoch 14/25\n",
            "1563/1563 [==============================] - 50s 32ms/step - loss: 1.5417 - accuracy: 0.4510\n",
            "Epoch 15/25\n",
            "1563/1563 [==============================] - 49s 31ms/step - loss: 1.5295 - accuracy: 0.4531\n",
            "Epoch 16/25\n",
            "1563/1563 [==============================] - 50s 32ms/step - loss: 1.5341 - accuracy: 0.4512\n",
            "Epoch 17/25\n",
            "1563/1563 [==============================] - 49s 31ms/step - loss: 1.5354 - accuracy: 0.4486\n",
            "Epoch 18/25\n",
            "1563/1563 [==============================] - 50s 32ms/step - loss: 1.5278 - accuracy: 0.4528\n",
            "Epoch 19/25\n",
            "1563/1563 [==============================] - 49s 31ms/step - loss: 1.5287 - accuracy: 0.4533\n",
            "Epoch 20/25\n",
            "1563/1563 [==============================] - 49s 31ms/step - loss: 1.5249 - accuracy: 0.4545\n",
            "Epoch 21/25\n",
            "1563/1563 [==============================] - 50s 32ms/step - loss: 1.5194 - accuracy: 0.4548\n",
            "Epoch 22/25\n",
            "1563/1563 [==============================] - 49s 31ms/step - loss: 1.5152 - accuracy: 0.4554\n",
            "Epoch 23/25\n",
            "1563/1563 [==============================] - 50s 32ms/step - loss: 1.5138 - accuracy: 0.4570\n",
            "Epoch 24/25\n",
            "1563/1563 [==============================] - 50s 32ms/step - loss: 1.5145 - accuracy: 0.4577\n",
            "Epoch 25/25\n",
            "1563/1563 [==============================] - 49s 32ms/step - loss: 1.5095 - accuracy: 0.4629\n",
            "313/313 [==============================] - 5s 15ms/step - loss: 1.5728 - accuracy: 0.4416\n",
            "\n",
            "\n",
            "For LR =  0.01\n",
            "Epoch 1/25\n",
            "1563/1563 [==============================] - 50s 32ms/step - loss: 2.3065 - accuracy: 0.0994\n",
            "Epoch 2/25\n",
            "1563/1563 [==============================] - 51s 32ms/step - loss: 2.3062 - accuracy: 0.1001\n",
            "Epoch 3/25\n",
            "1563/1563 [==============================] - 51s 32ms/step - loss: 2.3061 - accuracy: 0.1006\n",
            "Epoch 4/25\n",
            "1563/1563 [==============================] - 49s 31ms/step - loss: 2.3060 - accuracy: 0.0979\n",
            "Epoch 5/25\n",
            "1563/1563 [==============================] - 51s 32ms/step - loss: 2.3062 - accuracy: 0.0996\n",
            "Epoch 6/25\n",
            "1563/1563 [==============================] - 49s 32ms/step - loss: 2.3063 - accuracy: 0.1006\n",
            "Epoch 7/25\n",
            "1563/1563 [==============================] - 49s 32ms/step - loss: 2.3066 - accuracy: 0.1012\n",
            "Epoch 8/25\n",
            "1563/1563 [==============================] - 50s 32ms/step - loss: 2.3063 - accuracy: 0.1010\n",
            "Epoch 9/25\n",
            "1563/1563 [==============================] - 49s 31ms/step - loss: 2.3060 - accuracy: 0.1014\n",
            "Epoch 10/25\n",
            "1563/1563 [==============================] - 49s 31ms/step - loss: 2.3061 - accuracy: 0.1007\n",
            "Epoch 11/25\n",
            "1563/1563 [==============================] - 49s 31ms/step - loss: 2.3061 - accuracy: 0.0993\n",
            "Epoch 12/25\n",
            "1563/1563 [==============================] - 50s 32ms/step - loss: 2.3065 - accuracy: 0.0979\n",
            "Epoch 13/25\n",
            "1563/1563 [==============================] - 49s 31ms/step - loss: 2.3060 - accuracy: 0.0999\n",
            "Epoch 14/25\n",
            "1563/1563 [==============================] - 49s 31ms/step - loss: 2.3059 - accuracy: 0.1009\n",
            "Epoch 15/25\n",
            "1563/1563 [==============================] - 49s 31ms/step - loss: 2.3064 - accuracy: 0.1008\n",
            "Epoch 16/25\n",
            "1563/1563 [==============================] - 50s 32ms/step - loss: 2.3067 - accuracy: 0.0998\n",
            "Epoch 17/25\n",
            "1563/1563 [==============================] - 49s 31ms/step - loss: 2.3060 - accuracy: 0.0998\n",
            "Epoch 18/25\n",
            "1563/1563 [==============================] - 49s 31ms/step - loss: 2.3062 - accuracy: 0.1008\n",
            "Epoch 19/25\n",
            "1563/1563 [==============================] - 50s 32ms/step - loss: 2.3062 - accuracy: 0.0995\n",
            "Epoch 20/25\n",
            "1563/1563 [==============================] - 49s 31ms/step - loss: 2.3062 - accuracy: 0.1006\n",
            "Epoch 21/25\n",
            "1563/1563 [==============================] - 49s 31ms/step - loss: 2.3061 - accuracy: 0.1000\n",
            "Epoch 22/25\n",
            "1563/1563 [==============================] - 50s 32ms/step - loss: 2.3067 - accuracy: 0.1004\n",
            "Epoch 23/25\n",
            "1563/1563 [==============================] - 49s 31ms/step - loss: 2.3062 - accuracy: 0.0984\n",
            "Epoch 24/25\n",
            "1563/1563 [==============================] - 49s 31ms/step - loss: 2.3063 - accuracy: 0.1003\n",
            "Epoch 25/25\n",
            "1563/1563 [==============================] - 50s 32ms/step - loss: 2.3062 - accuracy: 0.0983\n",
            "313/313 [==============================] - 5s 15ms/step - loss: 2.3086 - accuracy: 0.1000\n",
            "\n",
            "\n",
            "For LR =  0.1\n",
            "Epoch 1/25\n",
            "1563/1563 [==============================] - 50s 32ms/step - loss: 3.1910 - accuracy: 0.1001\n",
            "Epoch 2/25\n",
            "1563/1563 [==============================] - 49s 32ms/step - loss: 2.3601 - accuracy: 0.1006\n",
            "Epoch 3/25\n",
            "1563/1563 [==============================] - 51s 32ms/step - loss: 2.3350 - accuracy: 0.0977\n",
            "Epoch 4/25\n",
            "1563/1563 [==============================] - 49s 32ms/step - loss: 2.3313 - accuracy: 0.1010\n",
            "Epoch 5/25\n",
            "1563/1563 [==============================] - 50s 32ms/step - loss: 2.3400 - accuracy: 0.0997\n",
            "Epoch 6/25\n",
            "1563/1563 [==============================] - 49s 31ms/step - loss: 2.3621 - accuracy: 0.1020\n",
            "Epoch 7/25\n",
            "1563/1563 [==============================] - 50s 32ms/step - loss: 2.3545 - accuracy: 0.1000\n",
            "Epoch 8/25\n",
            "1563/1563 [==============================] - 49s 31ms/step - loss: 2.3717 - accuracy: 0.1014\n",
            "Epoch 9/25\n",
            "1563/1563 [==============================] - 50s 32ms/step - loss: 2.3660 - accuracy: 0.0991\n",
            "Epoch 10/25\n",
            "1563/1563 [==============================] - 50s 32ms/step - loss: 2.3679 - accuracy: 0.1005\n",
            "Epoch 11/25\n",
            "1563/1563 [==============================] - 49s 31ms/step - loss: 2.3730 - accuracy: 0.0977\n",
            "Epoch 12/25\n",
            "1563/1563 [==============================] - 50s 32ms/step - loss: 2.3727 - accuracy: 0.1002\n",
            "Epoch 13/25\n",
            "1563/1563 [==============================] - 50s 32ms/step - loss: 2.3743 - accuracy: 0.0995\n",
            "Epoch 14/25\n",
            "1563/1563 [==============================] - 49s 31ms/step - loss: 2.3676 - accuracy: 0.1001\n",
            "Epoch 15/25\n",
            "1563/1563 [==============================] - 50s 32ms/step - loss: 2.3734 - accuracy: 0.1010\n",
            "Epoch 16/25\n",
            "1563/1563 [==============================] - 50s 32ms/step - loss: 2.3733 - accuracy: 0.0992\n",
            "Epoch 17/25\n",
            "1563/1563 [==============================] - 49s 31ms/step - loss: 2.3744 - accuracy: 0.1010\n",
            "Epoch 18/25\n",
            "1563/1563 [==============================] - 50s 32ms/step - loss: 2.3711 - accuracy: 0.0982\n",
            "Epoch 19/25\n",
            "1563/1563 [==============================] - 50s 32ms/step - loss: 2.3704 - accuracy: 0.0995\n",
            "Epoch 20/25\n",
            "1563/1563 [==============================] - 48s 31ms/step - loss: 2.3806 - accuracy: 0.0981\n",
            "Epoch 21/25\n",
            "1563/1563 [==============================] - 50s 32ms/step - loss: 2.3715 - accuracy: 0.0977\n",
            "Epoch 22/25\n",
            "1563/1563 [==============================] - 50s 32ms/step - loss: 2.3731 - accuracy: 0.1006\n",
            "Epoch 23/25\n",
            "1563/1563 [==============================] - 49s 31ms/step - loss: 2.3742 - accuracy: 0.1024\n",
            "Epoch 24/25\n",
            "1563/1563 [==============================] - 50s 32ms/step - loss: 2.3671 - accuracy: 0.0988\n",
            "Epoch 25/25\n",
            "1563/1563 [==============================] - 48s 31ms/step - loss: 2.3752 - accuracy: 0.1023\n",
            "313/313 [==============================] - 5s 16ms/step - loss: 2.3792 - accuracy: 0.1000\n",
            "\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Learning rate vs Accuracy"
      ],
      "metadata": {
        "id": "hUBBNkIqM8kY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "plt.plot(lst_lr,acc_lst)\n",
        "plt.title(\"Learning rate vs Accuracy\")\n",
        "plt.ylabel(\"Accuracy\")\n",
        "plt.xlabel(\"Learning rate\")\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 295
        },
        "id": "s4-ZP2mBDonh",
        "outputId": "648032b4-25cb-4f4f-b79a-cd4ca5904930"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Learning rate vs Loss"
      ],
      "metadata": {
        "id": "NMl4T3e3NC_4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "plt.plot(lst_lr,loss_lst)\n",
        "plt.title(\"Learning rate vs Loss\")\n",
        "plt.ylabel(\"Loss\")\n",
        "plt.xlabel(\"Learning rate\")\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "_PW4YrvSLgwP",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 295
        },
        "outputId": "d509539e-3b14-40ac-dae4-bebc435b0899"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYIAAAEWCAYAAABrDZDcAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+WH4yJAAAgAElEQVR4nO3deZwdZZ3v8c83vaTTSchCmpANAogoCLjE5brCOFcBHdAZ9V71oqJc1HFUXi6D2zg4M851RS/XUYaXIqOD4IYziAFBRVEQNSAkJBGH1W6SkE66s3an08vv/lF1kpPO6U53zqk+S33fr9d5UefUU6d+1Sc8v3qeeuopRQRmZpZf06odgJmZVZcTgZlZzjkRmJnlnBOBmVnOORGYmeWcE4GZWc45EVjDkfQiSQ9UOw6zeuFEYBUl6VFJf17NGCLilxFxUjVjKJB0hqSuGoij6r+L1S4nAqs7kpqqHQOAEv5/yOqe/xHblJA0TdKHJD0kaauk70iaX7T+u5I2Sdou6XZJpxStu1rSVyStlLQbODM9w/2ApNXpNt+W1JaWP+AsfLyy6fq/lbRR0gZJF0oKSU8a4zh+LumTku4A+oDjJV0gab2knZIelvT2tOxM4CZgsaRd6Wvxof4Wo/a3XtIri943S+qW9ExJbZL+Pf2ObZJ+J2nhJH+X6ZK+mB77hnR5erpugaQb0+/ukfTLQuKTdImkx9NjfkDSSyezX6stTgQ2Vd4NvAp4CbAY6AX+pWj9TcCJwFHAPcA1o7Z/A/BJYDbwq/Sz1wFnAccBpwFvGWf/JctKOgt4H/DnwJOAMyZwLOcDF6WxPAZsBl4JHAFcAHxB0jMjYjdwNrAhImalrw0T+FsUuxZ4fdH7lwNbIuIe4M3AHGAZcCTwDqB/AvEX+yjwPODpwOnAc4CPpeveD3QBHcBC4CNASDoJ+Bvg2RExO43p0Unu12qIE4FNlXcAH42IrogYAC4FXiOpGSAiroqInUXrTpc0p2j7/4yIOyJiJCL2pJ9dHhEbIqIH+CFJZTaWscq+Dvh6RKyNiL5034dydVp+KCIGI+JHEfFQJH4B3AK86HD/FqN8CzhXUnv6/g0kyQFgkCQBPCkihiPi7ojYMYH4i70R+IeI2BwR3cAnSBJd4fsXAcemx/nLSCYnGwamAydLaomIRyPioUnu12qIE4FNlWOBH6TdDNuA9SQVykJJTZI+lXaV7GD/2eWCou07S3znpqLlPmDWOPsfq+ziUd9daj+jHVBG0tmS7kq7T7YB53Bg7KON+bcYXTAiHkzX/0WaDM4lSQ4A3wR+DFyXdut8RlLLBOIvtpikVVPwWPoZwGeBB4Fb0i6vDxXFdDFJAtss6TpJi7G65URgU6UTODsi5ha92iLicZKz3PNIumfmAMvTbVS0fVbT5G4Elha9XzaBbfbFkvanfx/4HLAwIuYCK9kfe6m4x/tblFLoHjoPWJdWxKRn6Z+IiJOB55N0T71pAvEX20CSmAqOST8jbaG9PyKOJ0lA7ytcC4iIb0XEC9NtA/j0JPdrNcSJwLLQkl7ILLyagSuAT0o6FkBSh6Tz0vKzgQFgK9AO/PMUxvod4AJJT03PuP9uktu3knSTdANDks4GXla0/gngyFHdXOP9LUq5Lv3Od7K/NYCkMyWdqmQU1Q6SrpyRcb6n1O9yLfCxNIYFwMeBf0+//5WSniRJwHaSVsuIpJMk/VmaBPeQXJcYb79W45wILAsrSSqHwutS4P8CN5B0M+wE7gKem5b/BkmXxOPAunTdlIiIm4DLgdtIukEK+x6Y4PY7gfeQJJRektbNDUXr/0BS2T6cdgUtZvy/Ral9bAR+TXLW/+2iVUcD3yNJAuuBX5B0F42l1O/yT8AqYDWwhuRC/T+l5U8EfgLsSvf/5Yi4jSTxfQrYQtLldhTw4XH2azVOfjCN2X6SngrcD0yPiKFqx2M2FdwisNyT9Op0PP08kr7uHzoJWJ44EZjB20nuBXiIpB/8ndUNx2xquWvIzCzn3CIwM8u5Uncy1rQFCxbE8uXLqx2GmVldufvuu7dEREepdXWXCJYvX86qVauqHYaZWV2R9NhY69w1ZGaWc04EZmY5l1kikLRM0m2S1klaK+m945R9tqQhSa/JKh4zMysty2sEQ8D7I+IeSbOBuyXdGhHrigul86R8mmTqXjMzm2KZtQgiYmP68IzCfCzrgSUlir6bZPbGzVnFYmZmY5uSawSSlgPPAH4z6vMlwKuBrxxi+4skrZK0qru7O6swzcxyKfNEIGkWyRn/xSWenvRF4JKIGHcK24i4MiJWRMSKjo6Sw2DNzOwwZXofQfq0pO8D10TE9SWKrCB5uhIkT3Q6R9JQRPxHlnGZmVVbRLBncIS+vUP07R1mz+AwfXuHRy0P0T84TH/6+bOOnceLn1z5k+HMEkH6MIuvAesj4rJSZSLiuKLyVwM3OgmYWS2ICAaGRpJKeHCY/r1D9O9NK+60ci5e17d3+IBKe//yUFI2rdyL10/WO884ob4SAfACkodgr5F0b/rZR0gehUdEXJHhvs2swUUEe4dHxqxkC5Vz6bPtoX3lD9h2MKns+9Mz8ZFJzsnZ2jyN9tYmZrQ0MaO1ifbWJtpbmpnT3sqiluT9jHR9stzMjJZptLc27yu/f9tm2lubaGvZ//m0aTp0EIchs0QQEb/iwGfOHqr8W7KKxcyqY3B4pKiCHhrjjDlZV1xZH1BBDx5cae9Jz8SHJ1lTtzZNoy2teIsr2dltzSw8YnpaCSfritfvX24uUZknn7c1T6O5qT7v0a27uYbMrHKGhkdGVcijujRGVdx9afdIqcq51Nn20CQr6uZpOuiMub21iZmtzSyYNb1EBd18wNn3gctFlXa6rqVOK+qsORGY1bDhkdhXAe/ZO0JfcQV8QN/18L5+69GVeXHXyOj1e4cn98z5aWKMbowm5rW3JsslK+ZmZrRO21c5H1SZp2Vbm11RV4MTgVkZRkaCPUMHV7LjXSDsH7d/eviASn1gaHIVtURaEScVb3vL/kr26CNaRlXQk+8CaW2aRjrKzxqIE4E1tMIQveLK+ZD90wecWQ+NquCLK/Ah9gxOrqIGRvUt7z9rPmp224FdG6O7SFr2d3MccNZdtG56sytqmzwnAquqg4foFXVpDKYXBdN1+5cPPnNO+rNHDjrb7h8cZrJPYy1cTCyulNtampg/s5Wl85K+5xmt+8scWGmP3wXS1uKK2mqPE4GNqzBE76D+6X1nx0NjdH8c3D89erncIXoHniE3M3dGC4uOaCtxtl26m2NGiS6QLIfomdUqJ4IGUBiid8DdiIfqnx41UuSA0R6jbpY5nCF6pSrdwhC95Mx4f5/0uF0goy84tjTR5IrarKKcCKbA8Egc1D89uq+5VN/1ofqnC8uDw4c3RG9/d0WyPHN6M0cWDdGbdBdIepZer2OpzfLKiSBjm3fu4aWf+wU7B4YmvE3TNNHeklaso86s57W3Hnzn4iFGeuyvuJPPPJbazIo5EWRs/cad7BwY4q0vOI4Tjpp50I0ypW6G8RA9M5tKTgQZ6+rtA+DCFx3H4rkzqhyNmdnB3EeQsc6eflqaxMIj2qodiplZSU4EGevs7WPx3Bke6WJmNcuJIGNdvf0sm9de7TDMzMbkRJCxrp4+ls33tQEzq11OBBnq2zvE1t17WeoWgZnVMCeCDHX19gOwdJ5bBGZWu5wIMlQYOuoWgZnVMieCDHX2JC0CXyMws1rmRJChzp4+pjdPo2PW9GqHYmY2JieCDHX19rN03gxPF2FmNc2JIEOdvX0sm+/rA2ZW25wIMlRoEZiZ1bLMEoGkZZJuk7RO0lpJ7y1R5o2SVktaI+lOSadnFc9U27FnkO39g76r2MxqXpazjw4B74+IeyTNBu6WdGtErCsq8wjwkojolXQ2cCXw3AxjmjKdPcnQUXcNmVmtyywRRMRGYGO6vFPSemAJsK6ozJ1Fm9wFLM0qnqnmm8nMrF5MyTUCScuBZwC/GafY24Cbxtj+IkmrJK3q7u6ufIAZ2NcicNeQmdW4zBOBpFnA94GLI2LHGGXOJEkEl5RaHxFXRsSKiFjR0dGRXbAV1NXbz8zWJua2t1Q7FDOzcWX6hDJJLSRJ4JqIuH6MMqcBXwXOjoitWcYzlbrSoaO+h8DMal2Wo4YEfA1YHxGXjVHmGOB64PyI+GNWsVSDh46aWb3IskXwAuB8YI2ke9PPPgIcAxARVwAfB44EvpyeOQ9FxIoMY5oSEUFnTx/PO/7IaodiZnZIWY4a+hUwbr9IRFwIXJhVDNXS2zfI7r3DHjpqZnXBdxZnYP/00+4aMrPa50SQgX3TT3voqJnVASeCDOxrEfg5BGZWB5wIMtDZ28ecGS0c0eZ7CMys9jkRZKCzp99PJTOzuuFEkIGu3j6WzvX1ATOrD04EFRYRdPW6RWBm9cOJoMK6dw0wMDTCUo8YMrM64URQYfuGjrpFYGZ1womgwgpDR30PgZnVCyeCCis8kGaJ7yo2szrhRFBhnT19LJjVSntrpjN8m5lVjBNBhXX19rPE3UJmVkecCCqss7ePZe4WMrM64kRQQcMjwYZt/Z5+2szqihNBBT2xYw+Dw+Hpp82srjgRVFBnj4eOmln9cSKooMLQUbcIzKyeOBFUUGdvH5LvITCz+uJEUEFdvf0snN3G9OamaodiZjZhTgQV1NnT524hM6s7TgQVlEw/7QvFZlZfnAgqZHB4hI3b+90iMLO640RQIRu37WEkPHTUzOpPZolA0jJJt0laJ2mtpPeWKCNJl0t6UNJqSc/MKp6sFaafdovAzOpNllNkDgHvj4h7JM0G7pZ0a0SsKypzNnBi+nou8JX0v3Wns/AcAl8jMLM6k1mLICI2RsQ96fJOYD2wZFSx84BvROIuYK6kRVnFlKWu3n6apolFc9qqHYqZ2aRMyTUCScuBZwC/GbVqCdBZ9L6Lg5MFki6StErSqu7u7qzCLEtnTx9HH9FGc5Mvu5hZfcm81pI0C/g+cHFE7Dic74iIKyNiRUSs6OjoqGyAFdLZ2+/nFJtZXco0EUhqIUkC10TE9SWKPA4sK3q/NP2s7nT19rHUI4bMrA5lOWpIwNeA9RFx2RjFbgDelI4eeh6wPSI2ZhVTVvYMDvPEjgEPHTWzupTlqKEXAOcDayTdm372EeAYgIi4AlgJnAM8CPQBF2QYT2Y2bEtmHXXXkJnVo8wSQUT8CtAhygTwrqximCqd+6afdovAzOqPh7hUwL4H0rhFYGZ1yImgArp6+2lpEkfN9j0EZlZ/nAgqoLO3jyVzZ9A0bdyeMDOzmuREUAGeftrM6pkTQQV0+YE0ZlbHnAjK1Ld3iK2793rEkJnVLSeCMnXtGzrqFoGZ1ScngjLtHzrqFoGZ1ScngjIVWgSeXsLM6pUTQZk6e/poa5nGglmt1Q7FzOywOBGUqau3n6Xz2knm2DMzqz9OBGXq7PXQUTOrb04EZers6fP1ATOra04EZdjeP8iOPUOebM7M6poTQRm6epOho76ZzMzqmRNBGTx01MwagRNBGQo3k/lisZnVMyeCMnT19jNrejNz21uqHYqZ2WFzIihDVzp01PcQmFk9cyIoQ2dPvy8Um1ndcyI4TBFBV2+fh46aWd1zIjhMvX2D7N477BaBmdU9J4LDVLiHYJlHDJlZnZtQIpA0U9K0dPnJks6VNO5QGUlXSdos6f4x1s+R9ENJ90laK+mCyYdfPZ09hQfSuEVgZvVtoi2C24E2SUuAW4DzgasPsc3VwFnjrH8XsC4iTgfOAD4vqW7mcu4stAh8jcDM6txEE4Eiog/4S+DLEfFa4JTxNoiI24Ge8YoAs5WMvZyVlh2aYDxV19Xbx9z2Fma3+R4CM6tvE04Ekv4b8EbgR+lnTWXu+0vAU4ENwBrgvRExMsbOL5K0StKq7u7uMndbGcnQUbcGzKz+TTQRXAx8GPhBRKyVdDxwW5n7fjlwL7AYeDrwJUlHlCoYEVdGxIqIWNHR0VHmbiujq9fTT5tZY5hQIoiIX0TEuRHx6fSi8ZaIeE+Z+74AuD4SDwKPAE8p8zunRHIPgVsEZtYYJjpq6FuSjpA0E7gfWCfpg2Xu+0/AS9PvXwicBDxc5ndOie5dAwwMjbBsvlsEZlb/Jto1dHJE7ABeBdwEHEcycmhMkq4Ffg2cJKlL0tskvUPSO9Ii/wg8X9Ia4KfAJRGx5bCOYooVho66a8jMGkHzBMu1pPcNvAr4UkQMSorxNoiI1x9i/QbgZRPcf03Z/0Aadw2ZWf2baIvgX4FHgZnA7ZKOBXZkFVStKzyQxjeTmVkjmFCLICIuBy4v+ugxSWdmE1Lt6+zpY8GsVma0ljuC1sys+iZ6sXiOpMsKY/klfZ6kdZBLyYghtwbMrDFMtGvoKmAn8Lr0tQP4elZB1brO3j6PGDKzhjHRi8UnRMRfFb3/hKR7swio1g2PBBu29XPOqYuqHYqZWUVMtEXQL+mFhTeSXgD0ZxNSbXtixx4Gh8NDR82sYUy0RfAO4BuS5qTve4E3ZxNSbevs8dBRM2ssEx01dB9wemEuoIjYIeliYHWWwdWiwtBRXyMws0YxqSeURcSO9A5jgPdlEE/N6+ztQ4LFc9uqHYqZWUWU86hKVSyKOtLV28/C2W1Mb/Y9BGbWGMpJBONOMdGoOnv6/FQyM2so414jkLST0hW+gFzWhl29/TznuPnVDsPMrGLGTQQRMXuqAqkHg8MjbNzezzKPGDKzBlJO11DubNy2h5GApR4xZGYNxIlgEjz9tJk1IieCSehME4HvKjazRuJEMAmdPf00TROL5vgeAjNrHE4Ek9DV28eiOW00N/nPZmaNwzXaJHT29vv6gJk1HCeCSejq7fP1ATNrOE4EE7RncJgndgx4sjkzazhOBBO0YVvhgfXuGjKzxuJEMEGdnn7azBqUE8EE+YE0ZtaoMksEkq6StFnS/eOUOUPSvZLWSvpFVrFUQldvP61N01g42/cQmFljybJFcDVw1lgrJc0FvgycGxGnAK/NMJaydfb2sWTeDKZNy+VjGMysgWWWCCLidqBnnCJvAK6PiD+l5TdnFUsldPkeAjNrUNW8RvBkYJ6kn0u6W9Kbxioo6SJJqySt6u7unsIQ9+vq6WOp7yEwswZUzUTQDDwLeAXwcuDvJD25VMGIuDIiVkTEio6OjqmMEYDdA0Ns3b3XLQIza0jjPpgmY13A1ojYDeyWdDtwOvDHKsZU0uPbPHTUzBpXNVsE/wm8UFKzpHbgucD6KsYzpsLQUT+ZzMwaUWYtAknXAmcACyR1AX8PtABExBURsV7SzcBqYAT4akSMOdS0mtZv3AHAsUfOrHIkZmaVl1kiiIjXT6DMZ4HPZhVDpaxcs4lnHjOX+TNbqx2KmVnF+c7iQ3h0y27WbdzBOacuqnYoZmaZcCI4hJX3bwTgbCcCM2tQTgSHcNOaTTx92VyWzPWFYjNrTE4E4/jT1j7WPL6dc049utqhmJllxolgHPu6hZ7mbiEza1xOBOO4ac1GTl86xzeSmVlDcyIYQ2dPH/d1bfdFYjNreE4EY7gp7RZ6hROBmTU4J4IxrFyziVOXuFvIzBqfE0EJj2/r597ObZzt0UJmlgNOBCXctMbdQmaWH04EJaxcs5FTFh/hSebMLBecCEbZsK2fe/60zXMLmVluOBGMcvP9mwA4+2m+PmBm+eBEMMrKNRt5ytGzOb5jVrVDMTObEk4ERTZt38Oqx3p9kdjMcsWJoMjN6U1k55zmRGBm+eFEUGTlmk2ctHA2J7hbyMxyxIkgtXnHHn73WI9HC5lZ7jgRpG5eu4kIeMVpHi1kZvniRJD60eqNnHjULJ501Oxqh2JmNqWcCIDunQP89lF3C5lZPjkRUNwt5ERgZvmTWSKQdJWkzZLuP0S5Z0sakvSarGI5lJWrN3JCx0xOPMqjhcwsf7JsEVwNnDVeAUlNwKeBWzKMY1xbdg3wm0e28opTFyGpWmGYmVVNZokgIm4Heg5R7N3A94HNWcVxKD9eu4mRwI+kNLPcqto1AklLgFcDX6lWDJDMLXT8gpk85WiPFjKzfKrmxeIvApdExMihCkq6SNIqSau6u7srFsDWXQPc9XAyWsjdQmaWV81V3PcK4Lq0Al4AnCNpKCL+Y3TBiLgSuBJgxYoVUakAbln3BMMj4UdSmlmuVS0RRMRxhWVJVwM3lkoCWVq5ZiPLj2zn5EVHTOVuzcxqSmaJQNK1wBnAAkldwN8DLQARcUVW+52o3t17ufOhrbz9xce7W8jMci2zRBARr59E2bdkFcdYblm3ieGR8N3EZpZ7ub2zeOWaTRwzv51TFrtbyMzyLZeJYFvfXu54cItHC5mZkdNEcMu6JxgaCc7xaCEzs3wmglWP9rBgViunLplT7VDMzKoul4mge+cAi+bMcLeQmRl5TQS7Blgwq7XaYZiZ1YR8JoKdA3TMnl7tMMzMakLuEsHISLBl114nAjOzVO4Swbb+QYZHggWznAjMzCCHiaB75wCAWwRmZqn8JgK3CMzMgBwmgi27kkSwwC0CMzMgh4nAXUNmZgfKXyLYNcD05mnMnl7NZ/KYmdWO3CWCLTsHWDBruu8qNjNL5S4RdO/yzWRmZsXylwh8V7GZ2QFylwi27BrwzWRmZkVylQiGhkfYutvTS5iZFctVIujZvZcIDx01MyuWq0TQvatwV7GnoDYzK8hXIvDNZGZmB8lnIpjVVuVIzMxqR74Swb55htw1ZGZWkFkikHSVpM2S7h9j/RslrZa0RtKdkk7PKpaCLTv3MrO1ifZWTy9hZlaQZYvgauCscdY/ArwkIk4F/hG4MsNYAN9VbGZWSmanxhFxu6Tl46y/s+jtXcDSrGIp6N65xzeTmZmNUivXCN4G3DTWSkkXSVolaVV3d/dh78TPKjYzO1jVE4GkM0kSwSVjlYmIKyNiRUSs6OjoOOx9eZ4hM7ODVfWqqaTTgK8CZ0fE1iz3NTA0zPb+QXcNmZmNUrUWgaRjgOuB8yPij1nvb+uuvYBvJjMzGy2zFoGka4EzgAWSuoC/B1oAIuIK4OPAkcCX04fEDEXEiqzi8UPrzcxKy3LU0OsPsf5C4MKs9j9aIRH4ofVmZgeq+sXiqTK3vYWzTjmaxXM8vYSZWbHc3GK7Yvl8ViyfX+0wzMxqTm5aBGZmVpoTgZlZzjkRmJnlnBOBmVnOORGYmeWcE4GZWc45EZiZ5ZwTgZlZzikiqh3DpEjqBh47zM0XAFsqGE498DHng485H8o55mMjouQ8/nWXCMohaVWWE9vVIh9zPviY8yGrY3bXkJlZzjkRmJnlXN4SwZXVDqAKfMz54GPOh0yOOVfXCMzM7GB5axGYmdkoTgRmZjnXMIlA0lmSHpD0oKQPlVg/XdK30/W/kbS8aN2H088fkPTyqYy7HId7zJL+u6S7Ja1J//tnUx374Srnd07XHyNpl6QPTFXM5Sjz3/Vpkn4taW36W9fF4/nK+HfdIunf0mNdL+nDUx374ZrAMb9Y0j2ShiS9ZtS6N0v6r/T15sMKICLq/gU0AQ8BxwOtwH3AyaPK/DVwRbr8P4Fvp8snp+WnA8el39NU7WPK+JifASxOl58GPF7t48n6mIvWfw/4LvCBah9Pxr9xM7AaOD19f2QO/l2/AbguXW4HHgWWV/uYKnTMy4HTgG8Aryn6fD7wcPrfeenyvMnG0CgtgucAD0bEwxGxF7gOOG9UmfOAf0uXvwe8VJLSz6+LiIGIeAR4MP2+WnfYxxwRv4+IDenna4EZkqZPSdTlKed3RtKrgEdIjrkelHO8LwNWR8R9ABGxNSKGpyjucpRzzAHMlNQMzAD2AjumJuyyHPKYI+LRiFgNjIza9uXArRHRExG9wK3AWZMNoFESwRKgs+h9V/pZyTIRMQRsJzlLmsi2taicYy72V8A9ETGQUZyVdNjHLGkWcAnwiSmIs1LK+Y2fDISkH6ddCn87BfFWQjnH/D1gN7AR+BPwuYjoyTrgCiinDqpI/ZWbh9fbwSSdAnya5Oyx0V0KfCEidqUNhEbXDLwQeDbQB/xU0t0R8dPqhpWp5wDDwGKSbpJfSvpJRDxc3bBqX6O0CB4HlhW9X5p+VrJM2nScA2yd4La1qJxjRtJS4AfAmyLiocyjrYxyjvm5wGckPQpcDHxE0t9kHXCZyjneLuD2iNgSEX3ASuCZmUdcvnKO+Q3AzRExGBGbgTuAepiLqJw6qDL1V7UvlFToYkszyUWS49h/seWUUWXexYEXmL6TLp/CgReLH6Y+LqqVc8xz0/J/We3jmKpjHlXmUurjYnE5v/E84B6Si6bNwE+AV1T7mDI+5kuAr6fLM4F1wGnVPqZKHHNR2as5+GLxI+nvPS9dnj/pGKr9R6jgH/Mc4I8kV98/mn72D8C56XIbyWiRB4HfAscXbfvRdLsHgLOrfSxZHzPwMZK+1HuLXkdV+3iy/p2LvqMuEkG5xwv8L5IL4/cDn6n2sWR9zMCs9PO1aRL4YLWPpYLH/GySVt5uktbP2qJt35r+LR4ELjic/XuKCTOznGuUawRmZnaYnAjMzHLOicDMLOecCMzMcs6JwMws55wIrGFI2jXF+7tzivc3V9JfT+U+LR+cCMzGkN61OqaIeP4U73MuycybZhXlRGANTdIJkm5On7vwS0lPST//i3Qu+99L+omkhennl0r6pqQ7gG+m76+S9HNJD0t6T9F370r/e0a6/nuS/iDpmqIZT89JP7tb0uWSbiwR41sk3SDpZyRzAs2S9NN0srg1kgozUX4KOEHSvZI+m277QUm/k7RaUj1NqGe1pNp31PnlV6VewK4Sn/0UODFdfi7ws3R5Hvuf2X0h8Pl0+VLgbmBG0fs7SaYgWUByV2dL8f6AM0hmwFxKcnL1a5IJ39pIZoY8Li13LXBjiRjfQnLX6Pz0fTNwRLq8gOSOUZHMSX9/0XYvI3mYudL93gi8uNq/g1/19/Lso9aw0qmnnw98t2jG0cJzF5YC35a0iGR+l0eKNr0hIvqL3v8okmm6ByRtBhaSVNzFfhsRXel+7yWptHcBD0fynAtIEsFFY4R7a+yfMlnAP0t6Mcn880vSfY72svT1+/T9LOBE4PYx9mFWkhOBNbJpwLaIeHqJdZHGgEAAAAEpSURBVP8PuCwibpB0BsmZf8HuUWWLn9UwTOn/byZSZjzF+3wj0AE8KyIG0xlTSz1mUsD/iYh/neS+zA7gawTWsCJiB/CIpNcCKHF6unoO+6frPbznvB7aA8DxRc8R/h8T3G4OsDlNAmcCx6af7wRmF5X7MfDWtOWDpCWSjio7assdtwiskbRLKu6yuYzk7Porkj4GtJA8BvA+khbAdyX1Aj8jmQK4oiKiPx3uebOk3cDvJrjpNcAPJa0BVgF/SL9vq6Q7JN0P3BQRH5T0VODXadfXLpIZRzdX+lissXn2UbMMSZoVyVPRBPwL8F8R8YVqx2VWzF1DZtn63+nF47UkXT7uz7ea4xaBmVnOuUVgZpZzTgRmZjnnRGBmlnNOBGZmOedEYGaWc/8fBb63SRv7jwoAAAAASUVORK5CYII=\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**2.1 Explanation**\n",
        "With the increase in learning rate, the loss increases and the accuracy falls down"
      ],
      "metadata": {
        "id": "yWEvZdXZSrun"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**2.2**"
      ],
      "metadata": {
        "id": "9Rz9VefxNNW1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "lst_batch_size = [500, 1000, 10000, 20000] # default LR of adam optimizer is 0.001\n",
        "loss_acc_lst_batch = []\n",
        "loss_lst_batch = []\n",
        "acc_lst_batch = []\n",
        "\n",
        "for batch_size in lst_batch_size:\n",
        "    print(\"For LBatch = \", batch_size)\n",
        "    new_model = tf.keras.models.clone_model(cifar10)\n",
        "    new_model.compile(loss = 'sparse_categorical_crossentropy', optimizer= tf.keras.optimizers.Adam(learning_rate=0.001), metrics=['accuracy'])\n",
        "    new_model.fit(X_Train1, Y_Train1, epochs=25, batch_size=batch_size)\n",
        "    loss1, acc1 = new_model.evaluate(X_Test1, Y_Test1)\n",
        "    loss_acc_lst_batch.append([loss1, acc1])\n",
        "    loss_lst_batch.append(loss1)\n",
        "    acc_lst_batch.append(acc1)\n",
        "    print(\"\\n\")"
      ],
      "metadata": {
        "id": "ibkqr75ENQJc",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "29e967fc-c204-4b07-c248-ac7d39ecb4e6"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "For LBatch =  500\n",
            "Epoch 1/25\n",
            "100/100 [==============================] - 37s 365ms/step - loss: 1.9217 - accuracy: 0.3109\n",
            "Epoch 2/25\n",
            "100/100 [==============================] - 38s 382ms/step - loss: 1.6130 - accuracy: 0.4223\n",
            "Epoch 3/25\n",
            "100/100 [==============================] - 37s 367ms/step - loss: 1.4911 - accuracy: 0.4649\n",
            "Epoch 4/25\n",
            "100/100 [==============================] - 38s 380ms/step - loss: 1.4175 - accuracy: 0.4914\n",
            "Epoch 5/25\n",
            "100/100 [==============================] - 40s 403ms/step - loss: 1.3666 - accuracy: 0.5111\n",
            "Epoch 6/25\n",
            "100/100 [==============================] - 39s 386ms/step - loss: 1.3242 - accuracy: 0.5252\n",
            "Epoch 7/25\n",
            "100/100 [==============================] - 37s 370ms/step - loss: 1.2944 - accuracy: 0.5399\n",
            "Epoch 8/25\n",
            "100/100 [==============================] - 44s 443ms/step - loss: 1.2605 - accuracy: 0.5511\n",
            "Epoch 9/25\n",
            "100/100 [==============================] - 40s 397ms/step - loss: 1.2282 - accuracy: 0.5654\n",
            "Epoch 10/25\n",
            "100/100 [==============================] - 38s 377ms/step - loss: 1.2062 - accuracy: 0.5730\n",
            "Epoch 11/25\n",
            "100/100 [==============================] - 36s 365ms/step - loss: 1.1788 - accuracy: 0.5831\n",
            "Epoch 12/25\n",
            "100/100 [==============================] - 38s 383ms/step - loss: 1.1590 - accuracy: 0.5887\n",
            "Epoch 13/25\n",
            "100/100 [==============================] - 36s 364ms/step - loss: 1.1363 - accuracy: 0.5989\n",
            "Epoch 14/25\n",
            "100/100 [==============================] - 39s 387ms/step - loss: 1.1168 - accuracy: 0.6073\n",
            "Epoch 15/25\n",
            "100/100 [==============================] - 37s 365ms/step - loss: 1.0976 - accuracy: 0.6129\n",
            "Epoch 16/25\n",
            "100/100 [==============================] - 38s 379ms/step - loss: 1.0826 - accuracy: 0.6164\n",
            "Epoch 17/25\n",
            "100/100 [==============================] - 36s 363ms/step - loss: 1.0652 - accuracy: 0.6245\n",
            "Epoch 18/25\n",
            "100/100 [==============================] - 38s 378ms/step - loss: 1.0500 - accuracy: 0.6303\n",
            "Epoch 19/25\n",
            "100/100 [==============================] - 37s 365ms/step - loss: 1.0414 - accuracy: 0.6337\n",
            "Epoch 20/25\n",
            "100/100 [==============================] - 38s 377ms/step - loss: 1.0192 - accuracy: 0.6425\n",
            "Epoch 21/25\n",
            "100/100 [==============================] - 36s 365ms/step - loss: 1.0132 - accuracy: 0.6423\n",
            "Epoch 22/25\n",
            "100/100 [==============================] - 37s 366ms/step - loss: 0.9934 - accuracy: 0.6494\n",
            "Epoch 23/25\n",
            "100/100 [==============================] - 38s 377ms/step - loss: 0.9863 - accuracy: 0.6526\n",
            "Epoch 24/25\n",
            "100/100 [==============================] - 38s 380ms/step - loss: 0.9723 - accuracy: 0.6582\n",
            "Epoch 25/25\n",
            "100/100 [==============================] - 36s 365ms/step - loss: 0.9603 - accuracy: 0.6625\n",
            "313/313 [==============================] - 5s 15ms/step - loss: 1.1539 - accuracy: 0.6047\n",
            "\n",
            "\n",
            "For LBatch =  1000\n",
            "Epoch 1/25\n",
            "50/50 [==============================] - 37s 709ms/step - loss: 2.0150 - accuracy: 0.2774\n",
            "Epoch 2/25\n",
            "50/50 [==============================] - 37s 745ms/step - loss: 1.7064 - accuracy: 0.3957\n",
            "Epoch 3/25\n",
            "50/50 [==============================] - 40s 798ms/step - loss: 1.5504 - accuracy: 0.4436\n",
            "Epoch 4/25\n",
            "50/50 [==============================] - 44s 875ms/step - loss: 1.4683 - accuracy: 0.4710\n",
            "Epoch 5/25\n",
            "50/50 [==============================] - 43s 865ms/step - loss: 1.4255 - accuracy: 0.4892\n",
            "Epoch 6/25\n",
            "50/50 [==============================] - 43s 856ms/step - loss: 1.3758 - accuracy: 0.5066\n",
            "Epoch 7/25\n",
            "50/50 [==============================] - 36s 726ms/step - loss: 1.3515 - accuracy: 0.5168\n",
            "Epoch 8/25\n",
            "50/50 [==============================] - 38s 754ms/step - loss: 1.3180 - accuracy: 0.5325\n",
            "Epoch 9/25\n",
            "50/50 [==============================] - 40s 793ms/step - loss: 1.2905 - accuracy: 0.5441\n",
            "Epoch 10/25\n",
            "50/50 [==============================] - 40s 782ms/step - loss: 1.2594 - accuracy: 0.5538\n",
            "Epoch 11/25\n",
            "50/50 [==============================] - 40s 794ms/step - loss: 1.2415 - accuracy: 0.5597\n",
            "Epoch 12/25\n",
            "50/50 [==============================] - 41s 810ms/step - loss: 1.2164 - accuracy: 0.5706\n",
            "Epoch 13/25\n",
            "50/50 [==============================] - 38s 752ms/step - loss: 1.2040 - accuracy: 0.5731\n",
            "Epoch 14/25\n",
            "50/50 [==============================] - 36s 716ms/step - loss: 1.1957 - accuracy: 0.5790\n",
            "Epoch 15/25\n",
            "50/50 [==============================] - 36s 713ms/step - loss: 1.1648 - accuracy: 0.5900\n",
            "Epoch 16/25\n",
            "50/50 [==============================] - 38s 751ms/step - loss: 1.1605 - accuracy: 0.5919\n",
            "Epoch 17/25\n",
            "50/50 [==============================] - 36s 718ms/step - loss: 1.1401 - accuracy: 0.5998\n",
            "Epoch 18/25\n",
            "50/50 [==============================] - 37s 746ms/step - loss: 1.1344 - accuracy: 0.6003\n",
            "Epoch 19/25\n",
            "50/50 [==============================] - 36s 713ms/step - loss: 1.1126 - accuracy: 0.6092\n",
            "Epoch 20/25\n",
            "50/50 [==============================] - 37s 746ms/step - loss: 1.1103 - accuracy: 0.6128\n",
            "Epoch 21/25\n",
            "50/50 [==============================] - 36s 718ms/step - loss: 1.0992 - accuracy: 0.6135\n",
            "Epoch 22/25\n",
            "50/50 [==============================] - 37s 744ms/step - loss: 1.0863 - accuracy: 0.6183\n",
            "Epoch 23/25\n",
            "50/50 [==============================] - 36s 719ms/step - loss: 1.0709 - accuracy: 0.6235\n",
            "Epoch 24/25\n",
            "50/50 [==============================] - 36s 719ms/step - loss: 1.0564 - accuracy: 0.6299\n",
            "Epoch 25/25\n",
            "50/50 [==============================] - 37s 740ms/step - loss: 1.0547 - accuracy: 0.6306\n",
            "313/313 [==============================] - 5s 15ms/step - loss: 1.1368 - accuracy: 0.6016\n",
            "\n",
            "\n",
            "For LBatch =  10000\n",
            "Epoch 1/25\n",
            "5/5 [==============================] - 32s 6s/step - loss: 2.2849 - accuracy: 0.1288\n",
            "Epoch 2/25\n",
            "5/5 [==============================] - 30s 6s/step - loss: 2.2138 - accuracy: 0.2281\n",
            "Epoch 3/25\n",
            "5/5 [==============================] - 30s 6s/step - loss: 2.0952 - accuracy: 0.2598\n",
            "Epoch 4/25\n",
            "5/5 [==============================] - 31s 6s/step - loss: 2.0131 - accuracy: 0.2834\n",
            "Epoch 5/25\n",
            "5/5 [==============================] - 30s 6s/step - loss: 1.9527 - accuracy: 0.3067\n",
            "Epoch 6/25\n",
            "5/5 [==============================] - 32s 6s/step - loss: 1.9020 - accuracy: 0.3264\n",
            "Epoch 7/25\n",
            "5/5 [==============================] - 30s 6s/step - loss: 1.8571 - accuracy: 0.3402\n",
            "Epoch 8/25\n",
            "5/5 [==============================] - 30s 6s/step - loss: 1.8178 - accuracy: 0.3564\n",
            "Epoch 9/25\n",
            "5/5 [==============================] - 32s 6s/step - loss: 1.7856 - accuracy: 0.3673\n",
            "Epoch 10/25\n",
            "5/5 [==============================] - 30s 6s/step - loss: 1.7604 - accuracy: 0.3750\n",
            "Epoch 11/25\n",
            "5/5 [==============================] - 31s 6s/step - loss: 1.7328 - accuracy: 0.3838\n",
            "Epoch 12/25\n",
            "5/5 [==============================] - 30s 6s/step - loss: 1.7120 - accuracy: 0.3875\n",
            "Epoch 13/25\n",
            "5/5 [==============================] - 30s 6s/step - loss: 1.6938 - accuracy: 0.3938\n",
            "Epoch 14/25\n",
            "5/5 [==============================] - 32s 6s/step - loss: 1.6709 - accuracy: 0.4007\n",
            "Epoch 15/25\n",
            "5/5 [==============================] - 31s 6s/step - loss: 1.6598 - accuracy: 0.4029\n",
            "Epoch 16/25\n",
            "5/5 [==============================] - 32s 6s/step - loss: 1.6390 - accuracy: 0.4115\n",
            "Epoch 17/25\n",
            "5/5 [==============================] - 31s 6s/step - loss: 1.6199 - accuracy: 0.4176\n",
            "Epoch 18/25\n",
            "5/5 [==============================] - 30s 6s/step - loss: 1.6023 - accuracy: 0.4239\n",
            "Epoch 19/25\n",
            "5/5 [==============================] - 31s 6s/step - loss: 1.5901 - accuracy: 0.4295\n",
            "Epoch 20/25\n",
            "5/5 [==============================] - 32s 6s/step - loss: 1.5815 - accuracy: 0.4313\n",
            "Epoch 21/25\n",
            "5/5 [==============================] - 30s 6s/step - loss: 1.5639 - accuracy: 0.4388\n",
            "Epoch 22/25\n",
            "5/5 [==============================] - 30s 6s/step - loss: 1.5483 - accuracy: 0.4441\n",
            "Epoch 23/25\n",
            "5/5 [==============================] - 30s 6s/step - loss: 1.5391 - accuracy: 0.4471\n",
            "Epoch 24/25\n",
            "5/5 [==============================] - 32s 6s/step - loss: 1.5230 - accuracy: 0.4547\n",
            "Epoch 25/25\n",
            "5/5 [==============================] - 32s 6s/step - loss: 1.5136 - accuracy: 0.4564\n",
            "313/313 [==============================] - 6s 15ms/step - loss: 1.5103 - accuracy: 0.4568\n",
            "\n",
            "\n",
            "For LBatch =  20000\n",
            "Epoch 1/25\n",
            "3/3 [==============================] - 36s 9s/step - loss: 2.2904 - accuracy: 0.1232\n",
            "Epoch 2/25\n",
            "3/3 [==============================] - 29s 9s/step - loss: 2.2221 - accuracy: 0.1919\n",
            "Epoch 3/25\n",
            "3/3 [==============================] - 30s 9s/step - loss: 2.1279 - accuracy: 0.2319\n",
            "Epoch 4/25\n",
            "3/3 [==============================] - 28s 9s/step - loss: 2.0706 - accuracy: 0.2476\n",
            "Epoch 5/25\n",
            "3/3 [==============================] - 31s 9s/step - loss: 2.0294 - accuracy: 0.2686\n",
            "Epoch 6/25\n",
            "3/3 [==============================] - 29s 9s/step - loss: 2.0034 - accuracy: 0.2886\n",
            "Epoch 7/25\n",
            "3/3 [==============================] - 29s 9s/step - loss: 1.9844 - accuracy: 0.2895\n",
            "Epoch 8/25\n",
            "3/3 [==============================] - 29s 9s/step - loss: 1.9604 - accuracy: 0.3020\n",
            "Epoch 9/25\n",
            "3/3 [==============================] - 31s 9s/step - loss: 1.9429 - accuracy: 0.3084\n",
            "Epoch 10/25\n",
            "3/3 [==============================] - 30s 9s/step - loss: 1.9234 - accuracy: 0.3153\n",
            "Epoch 11/25\n",
            "3/3 [==============================] - 30s 9s/step - loss: 1.9070 - accuracy: 0.3223\n",
            "Epoch 12/25\n",
            "3/3 [==============================] - 29s 9s/step - loss: 1.8896 - accuracy: 0.3272\n",
            "Epoch 13/25\n",
            "3/3 [==============================] - 29s 9s/step - loss: 1.8738 - accuracy: 0.3339\n",
            "Epoch 14/25\n",
            "3/3 [==============================] - 30s 9s/step - loss: 1.8562 - accuracy: 0.3413\n",
            "Epoch 15/25\n",
            "3/3 [==============================] - 30s 9s/step - loss: 1.8378 - accuracy: 0.3498\n",
            "Epoch 16/25\n",
            "3/3 [==============================] - 29s 9s/step - loss: 1.8240 - accuracy: 0.3543\n",
            "Epoch 17/25\n",
            "3/3 [==============================] - 29s 9s/step - loss: 1.8101 - accuracy: 0.3585\n",
            "Epoch 18/25\n",
            "3/3 [==============================] - 29s 9s/step - loss: 1.7929 - accuracy: 0.3639\n",
            "Epoch 19/25\n",
            "3/3 [==============================] - 30s 9s/step - loss: 1.7835 - accuracy: 0.3683\n",
            "Epoch 20/25\n",
            "3/3 [==============================] - 30s 9s/step - loss: 1.7683 - accuracy: 0.3751\n",
            "Epoch 21/25\n",
            "3/3 [==============================] - 33s 10s/step - loss: 1.7502 - accuracy: 0.3806\n",
            "Epoch 22/25\n",
            "3/3 [==============================] - 29s 9s/step - loss: 1.7336 - accuracy: 0.3878\n",
            "Epoch 23/25\n",
            "3/3 [==============================] - 29s 9s/step - loss: 1.7157 - accuracy: 0.3946\n",
            "Epoch 24/25\n",
            "3/3 [==============================] - 31s 9s/step - loss: 1.6983 - accuracy: 0.4004\n",
            "Epoch 25/25\n",
            "3/3 [==============================] - 31s 10s/step - loss: 1.6856 - accuracy: 0.4054\n",
            "313/313 [==============================] - 5s 15ms/step - loss: 1.7072 - accuracy: 0.3884\n",
            "\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Batch Size vs Accuracy and Loss"
      ],
      "metadata": {
        "id": "1Bg7RF03PKfg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "plt.plot(lst_batch_size, acc_lst_batch, label=\"Accuracy\")\n",
        "plt.plot(lst_batch_size, loss_lst_batch, label=\"Loss\")\n",
        "plt.legend()\n",
        "plt.title(\"Batch size vs Accuracy\")\n",
        "plt.ylabel(\"Accuracy\")\n",
        "plt.xlabel(\"Batch size\")\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "EmigqXwOPOw5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 295
        },
        "outputId": "39f23bfa-af5b-4427-9d27-c7b694007474"
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Batch size vs Accuracy"
      ],
      "metadata": {
        "id": "Qxlo6wOUPW__"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "plt.plot(lst_batch_size, acc_lst_batch)\n",
        "plt.title(\"Batch size vs Accuracy\")\n",
        "plt.ylabel(\"Accuracy\")\n",
        "plt.xlabel(\"Batch size\")\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "jkpm13rgPZw7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 295
        },
        "outputId": "7893042f-3d90-4da2-8aa1-74d67e1f97d7"
      },
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Batch Size vs Loss"
      ],
      "metadata": {
        "id": "FbwIinKKPjpE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "plt.plot(lst_batch_size, loss_lst_batch)\n",
        "plt.title(\"Batch size vs Loss\")\n",
        "plt.ylabel(\"Loss\")\n",
        "plt.xlabel(\"Batch size\")\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "32ld57JLPhQL",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 295
        },
        "outputId": "1d59d723-91e5-4609-fb54-9d9a6bf60c45"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**2.2**\n",
        "As we can see from the above three graphs, the loss increases while accuracy decreases with increase in batch size which is similar to learning rate"
      ],
      "metadata": {
        "id": "bcor-2Eega0i"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**2.3**"
      ],
      "metadata": {
        "id": "LJUk7UkPPt9i"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Choosing lr = 0.005, epoch = 25, batch = 1000\n",
        "model = tf.keras.models.clone_model(cifar10)\n",
        "model.compile(loss = 'sparse_categorical_crossentropy', optimizer= tf.keras.optimizers.Adam(learning_rate=0.005), metrics=['accuracy'])\n",
        "model.fit(X_Train1, Y_Train1, epochs=25, batch_size=1000)\n",
        "loss__, acc__ = model.evaluate(X_Test1, Y_Test1)"
      ],
      "metadata": {
        "id": "Mg092gb-Phc4",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1bd0cb20-b8f5-4b49-f082-9d1b9ac0a51d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/25\n",
            "50/50 [==============================] - 22s 426ms/step - loss: 1.9983 - accuracy: 0.2710\n",
            "Epoch 2/25\n",
            "50/50 [==============================] - 22s 443ms/step - loss: 1.5278 - accuracy: 0.4456\n",
            "Epoch 3/25\n",
            "50/50 [==============================] - 21s 426ms/step - loss: 1.3848 - accuracy: 0.5022\n",
            "Epoch 4/25\n",
            "50/50 [==============================] - 21s 426ms/step - loss: 1.3201 - accuracy: 0.5282\n",
            "Epoch 5/25\n",
            "50/50 [==============================] - 21s 428ms/step - loss: 1.2520 - accuracy: 0.5521\n",
            "Epoch 6/25\n",
            "50/50 [==============================] - 21s 426ms/step - loss: 1.2169 - accuracy: 0.5656\n",
            "Epoch 7/25\n",
            "50/50 [==============================] - 21s 427ms/step - loss: 1.1695 - accuracy: 0.5846\n",
            "Epoch 8/25\n",
            "50/50 [==============================] - 21s 427ms/step - loss: 1.1536 - accuracy: 0.5912\n",
            "Epoch 9/25\n",
            "50/50 [==============================] - 21s 426ms/step - loss: 1.1145 - accuracy: 0.6041\n",
            "Epoch 10/25\n",
            "50/50 [==============================] - 21s 428ms/step - loss: 1.0893 - accuracy: 0.6122\n",
            "Epoch 11/25\n",
            "50/50 [==============================] - 21s 426ms/step - loss: 1.0681 - accuracy: 0.6203\n",
            "Epoch 12/25\n",
            "50/50 [==============================] - 21s 427ms/step - loss: 1.0213 - accuracy: 0.6390\n",
            "Epoch 13/25\n",
            "50/50 [==============================] - 21s 427ms/step - loss: 1.0078 - accuracy: 0.6429\n",
            "Epoch 14/25\n",
            "50/50 [==============================] - 22s 443ms/step - loss: 1.0018 - accuracy: 0.6475\n",
            "Epoch 15/25\n",
            "50/50 [==============================] - 21s 429ms/step - loss: 0.9793 - accuracy: 0.6534\n",
            "Epoch 16/25\n",
            "50/50 [==============================] - 21s 428ms/step - loss: 0.9559 - accuracy: 0.6616\n",
            "Epoch 17/25\n",
            "50/50 [==============================] - 21s 428ms/step - loss: 0.9502 - accuracy: 0.6646\n",
            "Epoch 18/25\n",
            "50/50 [==============================] - 21s 428ms/step - loss: 0.9362 - accuracy: 0.6697\n",
            "Epoch 19/25\n",
            "50/50 [==============================] - 21s 429ms/step - loss: 0.9024 - accuracy: 0.6818\n",
            "Epoch 20/25\n",
            "50/50 [==============================] - 21s 426ms/step - loss: 0.8985 - accuracy: 0.6832\n",
            "Epoch 21/25\n",
            "50/50 [==============================] - 21s 428ms/step - loss: 0.8749 - accuracy: 0.6898\n",
            "Epoch 22/25\n",
            "50/50 [==============================] - 21s 428ms/step - loss: 0.8592 - accuracy: 0.6960\n",
            "Epoch 23/25\n",
            "50/50 [==============================] - 22s 430ms/step - loss: 0.8594 - accuracy: 0.6967\n",
            "Epoch 24/25\n",
            "50/50 [==============================] - 21s 429ms/step - loss: 0.8367 - accuracy: 0.7041\n",
            "Epoch 25/25\n",
            "50/50 [==============================] - 22s 430ms/step - loss: 0.8261 - accuracy: 0.7075\n",
            "313/313 [==============================] - 3s 9ms/step - loss: 1.2012 - accuracy: 0.6028\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "By Choosing lr = 0.005, epoch = 25, batch = 1000 the training accuracy is 70.75% while test accuracy is 60.28%"
      ],
      "metadata": {
        "id": "Eue_rCxAhEkK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Choosing lr = 0.005, epoch = 25, batch = 500\n",
        "\n",
        "model1 = tf.keras.models.clone_model(cifar10)\n",
        "model1.compile(loss = 'sparse_categorical_crossentropy', optimizer= tf.keras.optimizers.Adam(learning_rate=0.005), metrics=['accuracy'])\n",
        "model1.fit(X_Train1, Y_Train1, epochs=25, batch_size=500)\n",
        "loss, acc = model1.evaluate(X_Test1, Y_Test1)"
      ],
      "metadata": {
        "id": "yeX3FDZPQPQv",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "abdfe01d-cc98-4867-cccc-e6c67f0d4c6f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/25\n",
            "100/100 [==============================] - 23s 222ms/step - loss: 1.7996 - accuracy: 0.3424\n",
            "Epoch 2/25\n",
            "100/100 [==============================] - 22s 223ms/step - loss: 1.4600 - accuracy: 0.4719\n",
            "Epoch 3/25\n",
            "100/100 [==============================] - 22s 222ms/step - loss: 1.3478 - accuracy: 0.5157\n",
            "Epoch 4/25\n",
            "100/100 [==============================] - 22s 221ms/step - loss: 1.2760 - accuracy: 0.5448\n",
            "Epoch 5/25\n",
            "100/100 [==============================] - 23s 230ms/step - loss: 1.2066 - accuracy: 0.5699\n",
            "Epoch 6/25\n",
            "100/100 [==============================] - 22s 222ms/step - loss: 1.1601 - accuracy: 0.5842\n",
            "Epoch 7/25\n",
            "100/100 [==============================] - 22s 223ms/step - loss: 1.1257 - accuracy: 0.5997\n",
            "Epoch 8/25\n",
            "100/100 [==============================] - 22s 222ms/step - loss: 1.0986 - accuracy: 0.6076\n",
            "Epoch 9/25\n",
            "100/100 [==============================] - 22s 222ms/step - loss: 1.0835 - accuracy: 0.6140\n",
            "Epoch 10/25\n",
            "100/100 [==============================] - 22s 223ms/step - loss: 1.0455 - accuracy: 0.6290\n",
            "Epoch 11/25\n",
            "100/100 [==============================] - 22s 222ms/step - loss: 1.0185 - accuracy: 0.6376\n",
            "Epoch 12/25\n",
            "100/100 [==============================] - 22s 222ms/step - loss: 1.0125 - accuracy: 0.6404\n",
            "Epoch 13/25\n",
            "100/100 [==============================] - 22s 221ms/step - loss: 0.9767 - accuracy: 0.6526\n",
            "Epoch 14/25\n",
            "100/100 [==============================] - 22s 223ms/step - loss: 0.9828 - accuracy: 0.6502\n",
            "Epoch 15/25\n",
            "100/100 [==============================] - 22s 223ms/step - loss: 0.9606 - accuracy: 0.6582\n",
            "Epoch 16/25\n",
            "100/100 [==============================] - 22s 223ms/step - loss: 0.9402 - accuracy: 0.6650\n",
            "Epoch 17/25\n",
            "100/100 [==============================] - 23s 232ms/step - loss: 0.9263 - accuracy: 0.6710\n",
            "Epoch 18/25\n",
            "100/100 [==============================] - 22s 224ms/step - loss: 0.9200 - accuracy: 0.6736\n",
            "Epoch 19/25\n",
            "100/100 [==============================] - 22s 224ms/step - loss: 0.8962 - accuracy: 0.6814\n",
            "Epoch 20/25\n",
            "100/100 [==============================] - 22s 224ms/step - loss: 0.8815 - accuracy: 0.6879\n",
            "Epoch 21/25\n",
            "100/100 [==============================] - 22s 224ms/step - loss: 0.8741 - accuracy: 0.6893\n",
            "Epoch 22/25\n",
            "100/100 [==============================] - 23s 225ms/step - loss: 0.8701 - accuracy: 0.6906\n",
            "Epoch 23/25\n",
            "100/100 [==============================] - 25s 247ms/step - loss: 0.8612 - accuracy: 0.6906\n",
            "Epoch 24/25\n",
            "100/100 [==============================] - 23s 228ms/step - loss: 0.8575 - accuracy: 0.6931\n",
            "Epoch 25/25\n",
            "100/100 [==============================] - 22s 225ms/step - loss: 0.8265 - accuracy: 0.7075\n",
            "313/313 [==============================] - 3s 9ms/step - loss: 1.2787 - accuracy: 0.5906\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "By Choosing lr = 0.005, epoch = 25, batch = 500 the training accuracy is 70.75% while test accuracy is 59.06% which is slightly less than the above"
      ],
      "metadata": {
        "id": "xkVuvhuhhVn3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Choosing lr = 0.005, epoch = 50, batch = 500 increasing epochs to improve accuracy metrics\n",
        "\n",
        "model2 = tf.keras.models.clone_model(cifar10)\n",
        "model2.compile(loss = 'sparse_categorical_crossentropy', optimizer= tf.keras.optimizers.Adam(learning_rate=0.005), metrics=['accuracy'])\n",
        "model2.fit(X_Train1, Y_Train1, epochs=50, batch_size=500)\n",
        "loss, acc = model2.evaluate(X_Test1, Y_Test1)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TLar6-e4TyTb",
        "outputId": "c8b4ad0e-2772-408d-c80a-e192a239b110"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/50\n",
            "100/100 [==============================] - 19s 188ms/step - loss: 1.8619 - accuracy: 0.3192\n",
            "Epoch 2/50\n",
            "100/100 [==============================] - 19s 189ms/step - loss: 1.5055 - accuracy: 0.4525\n",
            "Epoch 3/50\n",
            "100/100 [==============================] - 19s 189ms/step - loss: 1.3817 - accuracy: 0.4970\n",
            "Epoch 4/50\n",
            "100/100 [==============================] - 19s 189ms/step - loss: 1.2952 - accuracy: 0.5330\n",
            "Epoch 5/50\n",
            "100/100 [==============================] - 19s 189ms/step - loss: 1.2330 - accuracy: 0.5591\n",
            "Epoch 6/50\n",
            "100/100 [==============================] - 19s 188ms/step - loss: 1.1958 - accuracy: 0.5716\n",
            "Epoch 7/50\n",
            "100/100 [==============================] - 20s 197ms/step - loss: 1.1498 - accuracy: 0.5920\n",
            "Epoch 8/50\n",
            "100/100 [==============================] - 24s 240ms/step - loss: 1.1094 - accuracy: 0.6056\n",
            "Epoch 9/50\n",
            "100/100 [==============================] - 26s 260ms/step - loss: 1.0866 - accuracy: 0.6122\n",
            "Epoch 10/50\n",
            "100/100 [==============================] - 21s 214ms/step - loss: 1.0830 - accuracy: 0.6144\n",
            "Epoch 11/50\n",
            "100/100 [==============================] - 19s 191ms/step - loss: 1.0481 - accuracy: 0.6268\n",
            "Epoch 12/50\n",
            "100/100 [==============================] - 20s 199ms/step - loss: 1.0205 - accuracy: 0.6370\n",
            "Epoch 13/50\n",
            "100/100 [==============================] - 20s 197ms/step - loss: 0.9917 - accuracy: 0.6467\n",
            "Epoch 14/50\n",
            "100/100 [==============================] - 19s 189ms/step - loss: 0.9851 - accuracy: 0.6502\n",
            "Epoch 15/50\n",
            "100/100 [==============================] - 20s 201ms/step - loss: 0.9636 - accuracy: 0.6558\n",
            "Epoch 16/50\n",
            "100/100 [==============================] - 23s 232ms/step - loss: 0.9488 - accuracy: 0.6627\n",
            "Epoch 17/50\n",
            "100/100 [==============================] - 20s 197ms/step - loss: 0.9406 - accuracy: 0.6658\n",
            "Epoch 18/50\n",
            "100/100 [==============================] - 19s 190ms/step - loss: 0.9206 - accuracy: 0.6734\n",
            "Epoch 19/50\n",
            "100/100 [==============================] - 19s 190ms/step - loss: 0.9061 - accuracy: 0.6762\n",
            "Epoch 20/50\n",
            "100/100 [==============================] - 19s 190ms/step - loss: 0.8961 - accuracy: 0.6811\n",
            "Epoch 21/50\n",
            "100/100 [==============================] - 20s 196ms/step - loss: 0.8917 - accuracy: 0.6843\n",
            "Epoch 22/50\n",
            "100/100 [==============================] - 19s 189ms/step - loss: 0.8741 - accuracy: 0.6882\n",
            "Epoch 23/50\n",
            "100/100 [==============================] - 20s 197ms/step - loss: 0.8752 - accuracy: 0.6883\n",
            "Epoch 24/50\n",
            "100/100 [==============================] - 19s 189ms/step - loss: 0.8635 - accuracy: 0.6939\n",
            "Epoch 25/50\n",
            "100/100 [==============================] - 19s 188ms/step - loss: 0.8667 - accuracy: 0.6907\n",
            "Epoch 26/50\n",
            "100/100 [==============================] - 19s 188ms/step - loss: 0.8434 - accuracy: 0.6982\n",
            "Epoch 27/50\n",
            "100/100 [==============================] - 19s 191ms/step - loss: 0.8390 - accuracy: 0.6994\n",
            "Epoch 28/50\n",
            "100/100 [==============================] - 19s 190ms/step - loss: 0.8215 - accuracy: 0.7075\n",
            "Epoch 29/50\n",
            "100/100 [==============================] - 19s 190ms/step - loss: 0.8305 - accuracy: 0.7016\n",
            "Epoch 30/50\n",
            "100/100 [==============================] - 19s 189ms/step - loss: 0.8104 - accuracy: 0.7085\n",
            "Epoch 31/50\n",
            "100/100 [==============================] - 19s 189ms/step - loss: 0.8010 - accuracy: 0.7113\n",
            "Epoch 32/50\n",
            "100/100 [==============================] - 20s 196ms/step - loss: 0.8089 - accuracy: 0.7095\n",
            "Epoch 33/50\n",
            "100/100 [==============================] - 19s 189ms/step - loss: 0.7986 - accuracy: 0.7144\n",
            "Epoch 34/50\n",
            "100/100 [==============================] - 19s 189ms/step - loss: 0.7907 - accuracy: 0.7163\n",
            "Epoch 35/50\n",
            "100/100 [==============================] - 19s 190ms/step - loss: 0.7881 - accuracy: 0.7179\n",
            "Epoch 36/50\n",
            "100/100 [==============================] - 19s 189ms/step - loss: 0.7810 - accuracy: 0.7194\n",
            "Epoch 37/50\n",
            "100/100 [==============================] - 19s 190ms/step - loss: 0.7803 - accuracy: 0.7200\n",
            "Epoch 38/50\n",
            "100/100 [==============================] - 19s 190ms/step - loss: 0.7655 - accuracy: 0.7248\n",
            "Epoch 39/50\n",
            "100/100 [==============================] - 19s 191ms/step - loss: 0.7643 - accuracy: 0.7254\n",
            "Epoch 40/50\n",
            "100/100 [==============================] - 19s 192ms/step - loss: 0.7679 - accuracy: 0.7231\n",
            "Epoch 41/50\n",
            "100/100 [==============================] - 20s 199ms/step - loss: 0.7492 - accuracy: 0.7304\n",
            "Epoch 42/50\n",
            "100/100 [==============================] - 19s 191ms/step - loss: 0.7541 - accuracy: 0.7277\n",
            "Epoch 43/50\n",
            "100/100 [==============================] - 19s 190ms/step - loss: 0.7450 - accuracy: 0.7310\n",
            "Epoch 44/50\n",
            "100/100 [==============================] - 19s 192ms/step - loss: 0.7402 - accuracy: 0.7321\n",
            "Epoch 45/50\n",
            "100/100 [==============================] - 19s 192ms/step - loss: 0.7316 - accuracy: 0.7364\n",
            "Epoch 46/50\n",
            "100/100 [==============================] - 19s 190ms/step - loss: 0.7326 - accuracy: 0.7355\n",
            "Epoch 47/50\n",
            "100/100 [==============================] - 19s 190ms/step - loss: 0.7333 - accuracy: 0.7343\n",
            "Epoch 48/50\n",
            "100/100 [==============================] - 19s 189ms/step - loss: 0.7280 - accuracy: 0.7374\n",
            "Epoch 49/50\n",
            "100/100 [==============================] - 19s 190ms/step - loss: 0.7227 - accuracy: 0.7410\n",
            "Epoch 50/50\n",
            "100/100 [==============================] - 20s 196ms/step - loss: 0.7078 - accuracy: 0.7448\n",
            "313/313 [==============================] - 2s 7ms/step - loss: 1.4442 - accuracy: 0.5766\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "By Choosing lr = 0.005, epoch = 50, batch = 500 the training accuracy is 74.48% while test accuracy is 57.66% which is less than the previous. The train accuracy is increased while the test decreased."
      ],
      "metadata": {
        "id": "tu1R8n84hrEk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# lr = 0.005, epoch = 25, batch = 100 to check with different parameters\n",
        "\n",
        "model3 = tf.keras.models.clone_model(cifar10)\n",
        "model3.compile(loss = 'sparse_categorical_crossentropy', optimizer= tf.keras.optimizers.Adam(learning_rate=0.005), metrics=['accuracy'])\n",
        "model3.fit(X_Train1, Y_Train1, epochs=25, batch_size=100)\n",
        "loss, acc = model3.evaluate(X_Test1, Y_Test1)"
      ],
      "metadata": {
        "id": "hj9W7GECQSgo",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1783b884-ac4c-4f25-8cea-dbbd81a48063"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/25\n",
            "500/500 [==============================] - 22s 43ms/step - loss: 1.7257 - accuracy: 0.3617\n",
            "Epoch 2/25\n",
            "500/500 [==============================] - 22s 43ms/step - loss: 1.4877 - accuracy: 0.4623\n",
            "Epoch 3/25\n",
            "500/500 [==============================] - 22s 43ms/step - loss: 1.4005 - accuracy: 0.4955\n",
            "Epoch 4/25\n",
            "500/500 [==============================] - 22s 43ms/step - loss: 1.3540 - accuracy: 0.5167\n",
            "Epoch 5/25\n",
            "500/500 [==============================] - 21s 43ms/step - loss: 1.3099 - accuracy: 0.5329\n",
            "Epoch 6/25\n",
            "500/500 [==============================] - 22s 45ms/step - loss: 1.2772 - accuracy: 0.5432\n",
            "Epoch 7/25\n",
            "500/500 [==============================] - 22s 43ms/step - loss: 1.2569 - accuracy: 0.5574\n",
            "Epoch 8/25\n",
            "500/500 [==============================] - 22s 43ms/step - loss: 1.2283 - accuracy: 0.5646\n",
            "Epoch 9/25\n",
            "500/500 [==============================] - 22s 43ms/step - loss: 1.2095 - accuracy: 0.5740\n",
            "Epoch 10/25\n",
            "500/500 [==============================] - 21s 43ms/step - loss: 1.1907 - accuracy: 0.5784\n",
            "Epoch 11/25\n",
            "500/500 [==============================] - 21s 43ms/step - loss: 1.1646 - accuracy: 0.5892\n",
            "Epoch 12/25\n",
            "500/500 [==============================] - 22s 43ms/step - loss: 1.1434 - accuracy: 0.5944\n",
            "Epoch 13/25\n",
            "500/500 [==============================] - 22s 43ms/step - loss: 1.1298 - accuracy: 0.6006\n",
            "Epoch 14/25\n",
            "500/500 [==============================] - 22s 45ms/step - loss: 1.1104 - accuracy: 0.6078\n",
            "Epoch 15/25\n",
            "500/500 [==============================] - 22s 43ms/step - loss: 1.1037 - accuracy: 0.6089\n",
            "Epoch 16/25\n",
            "500/500 [==============================] - 22s 43ms/step - loss: 1.0900 - accuracy: 0.6118\n",
            "Epoch 17/25\n",
            "500/500 [==============================] - 22s 43ms/step - loss: 1.0845 - accuracy: 0.6148\n",
            "Epoch 18/25\n",
            "500/500 [==============================] - 22s 43ms/step - loss: 1.0680 - accuracy: 0.6216\n",
            "Epoch 19/25\n",
            "500/500 [==============================] - 21s 43ms/step - loss: 1.0598 - accuracy: 0.6235\n",
            "Epoch 20/25\n",
            "500/500 [==============================] - 22s 43ms/step - loss: 1.0420 - accuracy: 0.6317\n",
            "Epoch 21/25\n",
            "500/500 [==============================] - 22s 45ms/step - loss: 1.0352 - accuracy: 0.6348\n",
            "Epoch 22/25\n",
            "500/500 [==============================] - 22s 43ms/step - loss: 1.0251 - accuracy: 0.6358\n",
            "Epoch 23/25\n",
            "500/500 [==============================] - 22s 43ms/step - loss: 1.0178 - accuracy: 0.6389\n",
            "Epoch 24/25\n",
            "500/500 [==============================] - 22s 44ms/step - loss: 1.0100 - accuracy: 0.6442\n",
            "Epoch 25/25\n",
            "500/500 [==============================] - 22s 44ms/step - loss: 1.0021 - accuracy: 0.6451\n",
            "313/313 [==============================] - 2s 7ms/step - loss: 1.3954 - accuracy: 0.5296\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "By Choosing lr = 0.005, epoch = 25, batch = 100 the training accuracy is 64.51% while test accuracy is 52.66% which is less than the above in previous case"
      ],
      "metadata": {
        "id": "C5iZWiFYh8sd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# lr = 0.005, epoch = 20, batch = 1000 to check with different parameters\n",
        "\n",
        "model4 = tf.keras.models.clone_model(cifar10)\n",
        "model4.compile(loss = 'sparse_categorical_crossentropy', optimizer= tf.keras.optimizers.Adam(learning_rate=0.005), metrics=['accuracy'])\n",
        "model4.fit(X_Train1, Y_Train1, epochs=20, batch_size=1000)\n",
        "loss, acc = model4.evaluate(X_Test1, Y_Test1)"
      ],
      "metadata": {
        "id": "_kdR0BxMQU3h",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e131e640-bc34-43b9-eaa1-77d4bbdeb59f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/20\n",
            "50/50 [==============================] - 19s 368ms/step - loss: 1.9177 - accuracy: 0.2920\n",
            "Epoch 2/20\n",
            "50/50 [==============================] - 18s 367ms/step - loss: 1.5460 - accuracy: 0.4334\n",
            "Epoch 3/20\n",
            "50/50 [==============================] - 18s 366ms/step - loss: 1.4380 - accuracy: 0.4775\n",
            "Epoch 4/20\n",
            "50/50 [==============================] - 18s 370ms/step - loss: 1.3729 - accuracy: 0.5028\n",
            "Epoch 5/20\n",
            "50/50 [==============================] - 18s 369ms/step - loss: 1.3471 - accuracy: 0.5152\n",
            "Epoch 6/20\n",
            "50/50 [==============================] - 18s 368ms/step - loss: 1.2705 - accuracy: 0.5439\n",
            "Epoch 7/20\n",
            "50/50 [==============================] - 19s 384ms/step - loss: 1.2261 - accuracy: 0.5624\n",
            "Epoch 8/20\n",
            "50/50 [==============================] - 18s 368ms/step - loss: 1.1956 - accuracy: 0.5719\n",
            "Epoch 9/20\n",
            "50/50 [==============================] - 18s 368ms/step - loss: 1.1659 - accuracy: 0.5848\n",
            "Epoch 10/20\n",
            "50/50 [==============================] - 19s 370ms/step - loss: 1.1375 - accuracy: 0.5956\n",
            "Epoch 11/20\n",
            "50/50 [==============================] - 19s 371ms/step - loss: 1.0969 - accuracy: 0.6098\n",
            "Epoch 12/20\n",
            "50/50 [==============================] - 21s 419ms/step - loss: 1.0624 - accuracy: 0.6237\n",
            "Epoch 13/20\n",
            "50/50 [==============================] - 18s 369ms/step - loss: 1.0400 - accuracy: 0.6305\n",
            "Epoch 14/20\n",
            "50/50 [==============================] - 18s 368ms/step - loss: 1.0192 - accuracy: 0.6399\n",
            "Epoch 15/20\n",
            "50/50 [==============================] - 18s 370ms/step - loss: 1.0127 - accuracy: 0.6399\n",
            "Epoch 16/20\n",
            "50/50 [==============================] - 19s 385ms/step - loss: 0.9854 - accuracy: 0.6487\n",
            "Epoch 17/20\n",
            "50/50 [==============================] - 19s 374ms/step - loss: 0.9566 - accuracy: 0.6599\n",
            "Epoch 18/20\n",
            "50/50 [==============================] - 18s 369ms/step - loss: 0.9644 - accuracy: 0.6565\n",
            "Epoch 19/20\n",
            "50/50 [==============================] - 19s 376ms/step - loss: 0.9119 - accuracy: 0.6770\n",
            "Epoch 20/20\n",
            "50/50 [==============================] - 18s 368ms/step - loss: 0.9030 - accuracy: 0.6811\n",
            "313/313 [==============================] - 2s 7ms/step - loss: 1.1896 - accuracy: 0.5959\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "By Choosing lr = 0.005, epoch = 25, batch = 100 the training accuracy is 68.11% while test accuracy is 59.59% which is not the best performance."
      ],
      "metadata": {
        "id": "uPDo-yiyiPuS"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**2.3 Explanation**\n",
        "The best hyperparameters are:\n",
        "learning rate = 0.005,\n",
        "epoch = 25, \n",
        "batch = 1000\n"
      ],
      "metadata": {
        "id": "dGhQ2FItii0x"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**2.4**"
      ],
      "metadata": {
        "id": "uWMW8KVvi03B"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "Feed_Forward_model = tf.keras.models.Sequential()\n",
        "\n",
        "Feed_Forward_model.add(tf.keras.layers.Flatten())\n",
        "Feed_Forward_model.add(tf.keras.layers.Dense(6, activation='relu'))\n",
        "Feed_Forward_model.add(tf.keras.layers.Dense(16, activation='relu'))\n",
        "Feed_Forward_model.add(tf.keras.layers.Dense(120, activation='relu'))\n",
        "Feed_Forward_model.add(tf.keras.layers.Dense(84, activation='relu')) \n",
        "Feed_Forward_model.add(tf.keras.layers.Dense(10, activation='softmax'))\n",
        "Feed_Forward_model.compile(loss='sparse_categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "\n",
        "Feed_Forward_model.build(input_shape = (50000, 32, 32, 3))\n",
        "Feed_Forward_model.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QEGFi2M-BYm7",
        "outputId": "dc471e21-1afb-4f49-dec4-f7568b5c72b1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_1\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " flatten_1 (Flatten)         (50000, 3072)             0         \n",
            "                                                                 \n",
            " dense_5 (Dense)             (50000, 6)                18438     \n",
            "                                                                 \n",
            " dense_6 (Dense)             (50000, 16)               112       \n",
            "                                                                 \n",
            " dense_7 (Dense)             (50000, 120)              2040      \n",
            "                                                                 \n",
            " dense_8 (Dense)             (50000, 84)               10164     \n",
            "                                                                 \n",
            " dense_9 (Dense)             (50000, 10)               850       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 31,604\n",
            "Trainable params: 31,604\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "Feed_Forward_model.fit(X_Train1, Y_Train1, epochs=25, batch_size= 1000)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yjW7M87BplGS",
        "outputId": "3c6d030e-3360-40d4-ccd9-40253ceea128"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/25\n",
            "50/50 [==============================] - 2s 21ms/step - loss: 2.1914 - accuracy: 0.1711\n",
            "Epoch 2/25\n",
            "50/50 [==============================] - 1s 21ms/step - loss: 1.9901 - accuracy: 0.2424\n",
            "Epoch 3/25\n",
            "50/50 [==============================] - 1s 30ms/step - loss: 1.9436 - accuracy: 0.2538\n",
            "Epoch 4/25\n",
            "50/50 [==============================] - 1s 24ms/step - loss: 1.9319 - accuracy: 0.2585\n",
            "Epoch 5/25\n",
            "50/50 [==============================] - 1s 21ms/step - loss: 1.9240 - accuracy: 0.2625\n",
            "Epoch 6/25\n",
            "50/50 [==============================] - 1s 21ms/step - loss: 1.9173 - accuracy: 0.2623\n",
            "Epoch 7/25\n",
            "50/50 [==============================] - 1s 20ms/step - loss: 1.9120 - accuracy: 0.2645\n",
            "Epoch 8/25\n",
            "50/50 [==============================] - 1s 20ms/step - loss: 1.9138 - accuracy: 0.2655\n",
            "Epoch 9/25\n",
            "50/50 [==============================] - 1s 21ms/step - loss: 1.9067 - accuracy: 0.2699\n",
            "Epoch 10/25\n",
            "50/50 [==============================] - 1s 20ms/step - loss: 1.9055 - accuracy: 0.2684\n",
            "Epoch 11/25\n",
            "50/50 [==============================] - 1s 20ms/step - loss: 1.9024 - accuracy: 0.2692\n",
            "Epoch 12/25\n",
            "50/50 [==============================] - 1s 21ms/step - loss: 1.8999 - accuracy: 0.2706\n",
            "Epoch 13/25\n",
            "50/50 [==============================] - 1s 21ms/step - loss: 1.9000 - accuracy: 0.2722\n",
            "Epoch 14/25\n",
            "50/50 [==============================] - 1s 20ms/step - loss: 1.8984 - accuracy: 0.2737\n",
            "Epoch 15/25\n",
            "50/50 [==============================] - 1s 20ms/step - loss: 1.8956 - accuracy: 0.2724\n",
            "Epoch 16/25\n",
            "50/50 [==============================] - 1s 21ms/step - loss: 1.8962 - accuracy: 0.2739\n",
            "Epoch 17/25\n",
            "50/50 [==============================] - 1s 20ms/step - loss: 1.9014 - accuracy: 0.2716\n",
            "Epoch 18/25\n",
            "50/50 [==============================] - 1s 20ms/step - loss: 1.8922 - accuracy: 0.2737\n",
            "Epoch 19/25\n",
            "50/50 [==============================] - 1s 21ms/step - loss: 1.8915 - accuracy: 0.2752\n",
            "Epoch 20/25\n",
            "50/50 [==============================] - 1s 21ms/step - loss: 1.8904 - accuracy: 0.2757\n",
            "Epoch 21/25\n",
            "50/50 [==============================] - 1s 21ms/step - loss: 1.8895 - accuracy: 0.2747\n",
            "Epoch 22/25\n",
            "50/50 [==============================] - 1s 21ms/step - loss: 1.8887 - accuracy: 0.2773\n",
            "Epoch 23/25\n",
            "50/50 [==============================] - 1s 20ms/step - loss: 1.8885 - accuracy: 0.2776\n",
            "Epoch 24/25\n",
            "50/50 [==============================] - 1s 24ms/step - loss: 1.8918 - accuracy: 0.2772\n",
            "Epoch 25/25\n",
            "50/50 [==============================] - 1s 20ms/step - loss: 1.8872 - accuracy: 0.2788\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7fac1c53ced0>"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "score_FF = Feed_Forward_model.evaluate(X_Test1, Y_Test1)\n",
        "print('Test loss:', score_FF[0])\n",
        "print('Test accuracy:', score_FF[1])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Hvwdq5mTrYQT",
        "outputId": "a7dc88db-07ed-45a7-ec14-edb544628185"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "313/313 [==============================] - 0s 1ms/step - loss: 1.8828 - accuracy: 0.2784\n",
            "Test loss: 1.8828445672988892\n",
            "Test accuracy: 0.2784000039100647\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**2.4 a**\n",
        "The performance is too low with accuracy just 27.8%\n",
        "\n",
        "**2.4** **b**\n",
        "No of parameters is 31604. The parameters are less in this compared to 62,006. Despite this it took too long to train and the performace is alomst half of the other. So it is not worth it."
      ],
      "metadata": {
        "id": "fb2ssZz0Was9"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "F_iOszy7r63I"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}
